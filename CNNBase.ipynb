{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv(\"./data/labels_training.csv\",dtype=str)\n",
    "def append_ext(fn):\n",
    "    return fn+\".tif\"\n",
    "traindf[\"id\"]=traindf[\"id\"].apply(append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_train_images  = './data/training/'\n",
    "dir_test_images   = './data/testing/'\n",
    "# dir_train_labels  = './data/labels_training.csv'\n",
    "# dir_test_ids      = './data/sample_submission.csv'\n",
    "\n",
    "# labels_pd = pd.read_csv(dir_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "x_test = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, tags in traindf.values:\n",
    "    \n",
    "    training_data_file = 'data/training/{}'.format(f)\n",
    "    img = cv2.imread(training_data_file)\n",
    "    x.append(cv2.resize(img, (32, 32)))\n",
    "    y.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y, np.uint8)\n",
    "x = np.array(x, np.float16) / 255.\n",
    "\n",
    "### 33% percent validation set\n",
    "split = round(x.shape[0]*0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[y==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 250\n",
    "x_val, x_train, y_val, y_train = x[:split], x[split:], y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.7085 - acc: 0.6220\n",
      "Epoch 2/100\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.6437 - acc: 0.6633\n",
      "Epoch 3/100\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.6392 - acc: 0.6633\n",
      "Epoch 4/100\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.6292 - acc: 0.6640\n",
      "Epoch 5/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6194 - acc: 0.6687\n",
      "Epoch 6/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5915 - acc: 0.6687\n",
      "Epoch 7/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5811 - acc: 0.6840\n",
      "Epoch 8/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5559 - acc: 0.7000\n",
      "Epoch 9/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5356 - acc: 0.7087\n",
      "Epoch 10/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5283 - acc: 0.7280\n",
      "Epoch 11/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5296 - acc: 0.7093\n",
      "Epoch 12/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5457 - acc: 0.6947\n",
      "Epoch 13/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.5151 - acc: 0.7053\n",
      "Epoch 14/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4761 - acc: 0.7327\n",
      "Epoch 15/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4779 - acc: 0.7420\n",
      "Epoch 16/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4869 - acc: 0.7767\n",
      "Epoch 17/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4519 - acc: 0.7833\n",
      "Epoch 18/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4324 - acc: 0.8040\n",
      "Epoch 19/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4270 - acc: 0.8027\n",
      "Epoch 20/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4431 - acc: 0.7987\n",
      "Epoch 21/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4172 - acc: 0.8107\n",
      "Epoch 22/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4290 - acc: 0.7913\n",
      "Epoch 23/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4223 - acc: 0.8153\n",
      "Epoch 24/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3827 - acc: 0.8300\n",
      "Epoch 25/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3639 - acc: 0.8393\n",
      "Epoch 26/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3708 - acc: 0.8360\n",
      "Epoch 27/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3612 - acc: 0.8440\n",
      "Epoch 28/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3699 - acc: 0.8320\n",
      "Epoch 29/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3361 - acc: 0.8493\n",
      "Epoch 30/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3207 - acc: 0.8593\n",
      "Epoch 31/100\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3053 - acc: 0.8793\n",
      "Epoch 32/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2903 - acc: 0.8787\n",
      "Epoch 33/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3095 - acc: 0.8787\n",
      "Epoch 34/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2969 - acc: 0.8807\n",
      "Epoch 35/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2759 - acc: 0.8860\n",
      "Epoch 36/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2733 - acc: 0.8873\n",
      "Epoch 37/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2358 - acc: 0.9140\n",
      "Epoch 38/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2308 - acc: 0.9127\n",
      "Epoch 39/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2161 - acc: 0.9167\n",
      "Epoch 40/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2104 - acc: 0.9267\n",
      "Epoch 41/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2242 - acc: 0.9167\n",
      "Epoch 42/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2436 - acc: 0.9020\n",
      "Epoch 43/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2079 - acc: 0.9280\n",
      "Epoch 44/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1861 - acc: 0.9373\n",
      "Epoch 45/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1712 - acc: 0.9540\n",
      "Epoch 46/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1751 - acc: 0.9407\n",
      "Epoch 47/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1896 - acc: 0.9413\n",
      "Epoch 48/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1745 - acc: 0.9420\n",
      "Epoch 49/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1764 - acc: 0.9433\n",
      "Epoch 50/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1499 - acc: 0.9573\n",
      "Epoch 51/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1529 - acc: 0.9500\n",
      "Epoch 52/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1546 - acc: 0.9560\n",
      "Epoch 53/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1496 - acc: 0.9547\n",
      "Epoch 54/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1246 - acc: 0.9627\n",
      "Epoch 55/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1287 - acc: 0.9580\n",
      "Epoch 56/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1203 - acc: 0.9720\n",
      "Epoch 57/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1254 - acc: 0.9533\n",
      "Epoch 58/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1305 - acc: 0.9653\n",
      "Epoch 59/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1206 - acc: 0.9667\n",
      "Epoch 60/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1099 - acc: 0.9727\n",
      "Epoch 61/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1166 - acc: 0.9707\n",
      "Epoch 62/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1205 - acc: 0.9727\n",
      "Epoch 63/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1110 - acc: 0.9707\n",
      "Epoch 64/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0948 - acc: 0.9820\n",
      "Epoch 65/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1060 - acc: 0.9680\n",
      "Epoch 66/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1087 - acc: 0.9780\n",
      "Epoch 67/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0973 - acc: 0.9807\n",
      "Epoch 68/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0882 - acc: 0.9840\n",
      "Epoch 69/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0914 - acc: 0.9827\n",
      "Epoch 70/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0953 - acc: 0.9787\n",
      "Epoch 71/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0969 - acc: 0.9813\n",
      "Epoch 72/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0922 - acc: 0.9827\n",
      "Epoch 73/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0776 - acc: 0.9893\n",
      "Epoch 74/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0957 - acc: 0.9707\n",
      "Epoch 75/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0846 - acc: 0.9880\n",
      "Epoch 76/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0863 - acc: 0.9827\n",
      "Epoch 77/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0850 - acc: 0.9833\n",
      "Epoch 78/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0991 - acc: 0.9787\n",
      "Epoch 79/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0904 - acc: 0.9833\n",
      "Epoch 80/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0846 - acc: 0.9847\n",
      "Epoch 81/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0775 - acc: 0.9833\n",
      "Epoch 82/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0689 - acc: 0.9880\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0718 - acc: 0.9880\n",
      "Epoch 84/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0689 - acc: 0.9873\n",
      "Epoch 85/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1194 - acc: 0.9613\n",
      "Epoch 86/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1072 - acc: 0.9727\n",
      "Epoch 87/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0921 - acc: 0.9740\n",
      "Epoch 88/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0793 - acc: 0.9873\n",
      "Epoch 89/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0819 - acc: 0.9800\n",
      "Epoch 90/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1071 - acc: 0.9680\n",
      "Epoch 91/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0820 - acc: 0.9833\n",
      "Epoch 92/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0804 - acc: 0.9813\n",
      "Epoch 93/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0758 - acc: 0.9847\n",
      "Epoch 94/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0730 - acc: 0.9887\n",
      "Epoch 95/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0714 - acc: 0.9873\n",
      "Epoch 96/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0674 - acc: 0.9920\n",
      "Epoch 97/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0513 - acc: 0.9933\n",
      "Epoch 98/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0638 - acc: 0.9940\n",
      "Epoch 99/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0683 - acc: 0.9867\n",
      "Epoch 100/100\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0600 - acc: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8481c2a50>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = None\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(32, 32, 3)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "## TODO: Add validation data\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=100,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_prediction = model.predict(x, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y, training_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load test data\n",
    "dir_test_ids      = './data/sample_submission.csv'\n",
    "labels_pd = pd.read_csv(dir_test_ids)\n",
    "ids= labels_pd.id.values\n",
    "x_test = []\n",
    "for identifier in ids:\n",
    "    img = cv2.imread(\"./data/testing/\"+str(identifier)+'.tif')\n",
    "    x_test.append(cv2.resize(img, (32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test, np.float16) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = model.predict(x_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = pd.DataFrame({'id':    ids,\n",
    "                                'score':  test_prediction.ravel()})\n",
    "submission_file.to_csv('submission_basic_cnn.csv',\n",
    "                       columns=['id','score'],\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.50975585e-03, 6.85012937e-01, 1.90600753e-03,\n",
       "       1.51101977e-01, 6.91413879e-06, 7.74042010e-01, 5.59533596e-01,\n",
       "       1.13898218e-02, 9.87324476e-01, 6.48200512e-05, 1.24186277e-04,\n",
       "       3.39150429e-05, 9.38823521e-02, 4.79817390e-06, 1.08465552e-03,\n",
       "       1.14631355e-02, 9.42898631e-01, 8.57667923e-01, 9.04835761e-02,\n",
       "       5.34968376e-01, 7.86781311e-06, 8.13871622e-04, 0.00000000e+00,\n",
       "       7.73826540e-02, 9.15159822e-01, 8.26561451e-03, 2.12218165e-02,\n",
       "       5.87062299e-01, 4.56225872e-03, 8.51243556e-01, 8.70227814e-06,\n",
       "       3.48706245e-01, 8.79582405e-01, 3.20333242e-03, 2.56007284e-01,\n",
       "       9.96443212e-01, 2.08616257e-07, 9.94920790e-01, 0.00000000e+00,\n",
       "       9.79549766e-01, 8.40425491e-06, 8.80633473e-01, 2.91590691e-02,\n",
       "       5.25122881e-03, 1.05197847e-01, 2.96294689e-04, 1.93634629e-03,\n",
       "       1.37296885e-01, 2.48014927e-03, 9.91209507e-01, 9.97096241e-01,\n",
       "       3.60481650e-01, 9.97987509e-01, 8.30858946e-04, 1.19209290e-07,\n",
       "       9.92060304e-01, 8.94069672e-08, 8.28355551e-03, 4.05853987e-02,\n",
       "       8.90250921e-01, 9.11046028e-01, 0.00000000e+00, 2.20946223e-01,\n",
       "       8.94016743e-01, 4.02569771e-04, 3.87430191e-07, 0.00000000e+00,\n",
       "       2.21729279e-05, 8.13603401e-06, 1.81734562e-04, 6.34754002e-01,\n",
       "       3.71398330e-02, 7.44882584e-01, 5.06513894e-01, 8.66903245e-01,\n",
       "       5.06639481e-07, 3.64504158e-02, 1.19209290e-07, 7.94529915e-05,\n",
       "       1.51991844e-06, 7.82203197e-01, 9.37114894e-01, 1.04597360e-01,\n",
       "       9.56955850e-01, 9.41181123e-01, 1.66422129e-03, 9.69057798e-01,\n",
       "       0.00000000e+00, 4.23192978e-06, 7.02717364e-01, 9.49563861e-01,\n",
       "       9.59495664e-01, 1.99131161e-01, 2.58376360e-01, 5.78567326e-01,\n",
       "       1.01333857e-03, 9.78327751e-01, 7.35460877e-01, 9.37244475e-01,\n",
       "       1.06100738e-01, 9.95017052e-01, 9.93199527e-01, 2.39950418e-03,\n",
       "       1.27974153e-03, 5.98062396e-01, 8.64940286e-01, 2.41389871e-01,\n",
       "       2.35438347e-06, 0.00000000e+00, 2.38120556e-05, 1.08790994e-02,\n",
       "       8.01815629e-01, 4.31987047e-02, 1.07586384e-05, 9.37149525e-01,\n",
       "       9.91742492e-01, 4.11932111e-01, 3.92967463e-03, 2.28583813e-04,\n",
       "       9.36267376e-01, 2.83479691e-04, 9.65893388e-01, 6.08861446e-05,\n",
       "       3.87679935e-02, 2.73514092e-02, 4.50390577e-03, 9.63111997e-01,\n",
       "       9.90229487e-01, 9.82130051e-01, 9.42965984e-01, 2.68220901e-07,\n",
       "       3.90689075e-02, 1.49875879e-04, 3.70594859e-03, 5.40413260e-02,\n",
       "       1.15774572e-02, 9.88701820e-01, 6.13331795e-05, 1.62800580e-01,\n",
       "       6.12828135e-03, 1.02460384e-04, 0.00000000e+00, 2.79814005e-04,\n",
       "       2.61002779e-02, 8.98321867e-01, 3.67164612e-05, 1.47342682e-04,\n",
       "       8.18669796e-05, 9.46803808e-01, 8.90938461e-01, 3.16347182e-02,\n",
       "       1.32799149e-04, 2.89384604e-01, 4.10725534e-01, 5.71699619e-01,\n",
       "       8.62973332e-01, 9.98221159e-01, 9.85741913e-02, 1.26541257e-02,\n",
       "       1.11960441e-01, 6.92424178e-03, 1.75190091e-01, 3.39120626e-04,\n",
       "       1.16292536e-02, 3.48985195e-05, 4.71264124e-03, 2.41988599e-02,\n",
       "       5.25856972e-01, 4.44054604e-06, 9.69650388e-01, 9.79459524e-01,\n",
       "       0.00000000e+00, 8.82775307e-01, 9.62152004e-01, 9.30849314e-01,\n",
       "       0.00000000e+00, 9.16673958e-01, 9.86097932e-01, 1.74442351e-01,\n",
       "       2.35751271e-02, 9.44316387e-04, 8.69193494e-01, 1.85881853e-02,\n",
       "       9.56412017e-01, 1.19566917e-04, 2.74559855e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 8.61578465e-01, 2.47788429e-03, 0.00000000e+00,\n",
       "       1.70784593e-02, 9.55229342e-01, 1.01534128e-01, 1.95037574e-01,\n",
       "       1.72627807e-01, 9.87625837e-01, 1.01327896e-06, 1.01646483e-02,\n",
       "       1.19209290e-07, 9.03328776e-01, 7.34988093e-01, 9.96532559e-01,\n",
       "       9.98329520e-01, 1.45521760e-03, 9.38020945e-01, 0.00000000e+00,\n",
       "       2.50339508e-06, 7.74829030e-01, 2.45273113e-05, 3.84449959e-06,\n",
       "       9.89888191e-01, 3.27825546e-07, 5.13065100e-01, 5.96046448e-08,\n",
       "       4.34163809e-02, 9.90412176e-01, 6.69581771e-01, 9.94552374e-01,\n",
       "       3.18325937e-01, 2.69213319e-03, 8.92176330e-01, 8.69333744e-05,\n",
       "       8.14339519e-03, 0.00000000e+00, 9.01386797e-01, 8.34686458e-01,\n",
       "       8.94069672e-08, 9.71893430e-01, 0.00000000e+00, 1.17069483e-03,\n",
       "       1.56197101e-01, 1.81898206e-01, 7.15088844e-02, 9.94210720e-01,\n",
       "       2.77876735e-01, 4.84102368e-01, 0.00000000e+00, 9.64999199e-05,\n",
       "       2.90593117e-01, 3.00676942e-01, 7.89761543e-06, 0.00000000e+00,\n",
       "       1.46382451e-02, 3.69548798e-06, 9.43576813e-01, 0.00000000e+00,\n",
       "       8.67843628e-05, 1.17638767e-01, 8.39382410e-04, 2.76073396e-01,\n",
       "       5.06639481e-07, 9.35170531e-01, 9.96031702e-01, 9.41783190e-04,\n",
       "       8.22424889e-04, 6.55651093e-07, 1.19209290e-07, 9.81179893e-01,\n",
       "       1.78813934e-07, 1.84774399e-06, 4.39282358e-02, 1.08748674e-02,\n",
       "       9.66651380e-01, 4.97728586e-04, 6.78706169e-03, 3.80839407e-02,\n",
       "       3.57013941e-02, 1.76009536e-03, 9.87924814e-01, 9.80496407e-06,\n",
       "       1.78813934e-07, 6.94394112e-06, 2.90662050e-04, 7.92443752e-05,\n",
       "       3.55769962e-01, 9.54174042e-01, 9.75739241e-01, 0.00000000e+00,\n",
       "       9.93014216e-01, 9.45121050e-04, 2.41398811e-06, 4.08589840e-05,\n",
       "       8.58624697e-01, 8.48374784e-01, 9.98609900e-01, 5.13895154e-02,\n",
       "       2.29727030e-02, 9.73917961e-01, 1.09292597e-01, 7.13833630e-01,\n",
       "       1.52753204e-01, 1.27720535e-02, 8.11363339e-01, 1.34110451e-06,\n",
       "       3.63886356e-05, 9.69547391e-01, 8.68630707e-01, 5.96046448e-08,\n",
       "       6.23464584e-05, 7.28562474e-03, 2.08616257e-07, 8.52332890e-01,\n",
       "       0.00000000e+00, 4.97132540e-04, 5.96046448e-08, 6.88877881e-01,\n",
       "       9.65130150e-01, 7.79600143e-01, 1.63912773e-06, 9.82457399e-03,\n",
       "       9.77417469e-01, 7.73966312e-05, 7.74860382e-07, 9.99394059e-01,\n",
       "       2.95802861e-01, 3.02255154e-04, 5.69158196e-02, 8.29446852e-01,\n",
       "       9.74489808e-01, 7.74860382e-07, 5.66780567e-04, 3.75509262e-05,\n",
       "       1.16229057e-06, 6.52670860e-06, 1.51264668e-02, 2.86180198e-01,\n",
       "       1.12652779e-05, 8.82913232e-01, 3.53613198e-02, 6.69685602e-01,\n",
       "       5.53251028e-01, 5.27120292e-01, 9.27391827e-01, 5.60183525e-02,\n",
       "       1.24203563e-02, 2.72493064e-02, 3.87430191e-07, 4.57197428e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.45961952e-04, 2.33319402e-03,\n",
       "       2.00594068e-02, 9.74702001e-01, 9.82549489e-01, 9.00894403e-04,\n",
       "       2.98023224e-08, 9.24434602e-01, 4.63426113e-05, 9.67373431e-01,\n",
       "       1.74045563e-04, 7.59065151e-05, 8.74012709e-04, 0.00000000e+00,\n",
       "       1.78813934e-07, 9.71417308e-01, 9.74632800e-01, 6.84857368e-05,\n",
       "       3.75961542e-01, 4.93621349e-01, 3.66866589e-05, 6.68367743e-01,\n",
       "       9.46214080e-01, 1.32024288e-05, 8.79108906e-03, 5.57035208e-04,\n",
       "       7.51178861e-02, 9.43678737e-01, 2.98023224e-07, 1.11240149e-03,\n",
       "       9.91651177e-01, 2.98023224e-08, 7.94941783e-01, 1.73580647e-02,\n",
       "       4.48557258e-01, 6.97140932e-01, 8.86064172e-02, 1.40485168e-03,\n",
       "       8.94069672e-08, 5.28051853e-02, 9.89209950e-01, 5.04553318e-04,\n",
       "       4.43771482e-03, 4.04000282e-04, 9.53381419e-01, 3.90340596e-01,\n",
       "       9.39309418e-01, 8.85260105e-03, 5.01527071e-01, 2.18300790e-01,\n",
       "       1.87754631e-06, 4.00001019e-01, 9.76150095e-01, 4.76837158e-07,\n",
       "       2.08616257e-07, 3.33786011e-05, 1.32524371e-02, 4.53562230e-01,\n",
       "       4.42802906e-04, 9.93182600e-01, 4.24355268e-04, 7.42256641e-04,\n",
       "       9.85264778e-05, 3.27825546e-06, 9.66634870e-01, 1.17981732e-02,\n",
       "       5.00640273e-03, 1.35332346e-04, 4.02382821e-01, 2.67824531e-03,\n",
       "       9.32438016e-01, 7.43679285e-01, 1.20103359e-04, 0.00000000e+00,\n",
       "       8.93406391e-01, 0.00000000e+00, 4.13209200e-04, 5.66244125e-07,\n",
       "       1.63912773e-06, 1.70975924e-04, 5.91725111e-04, 6.87445402e-01,\n",
       "       1.63823366e-04, 8.53671849e-01, 1.49011612e-07, 1.78813934e-06,\n",
       "       8.20636749e-04, 4.97739017e-02, 9.65209126e-01, 1.26743436e-01,\n",
       "       1.61826611e-04, 1.71095133e-04, 0.00000000e+00, 1.20997429e-04,\n",
       "       6.00511253e-01, 7.44869709e-01, 2.68220901e-07, 2.80380249e-04,\n",
       "       1.10268593e-06, 5.96046448e-08, 0.00000000e+00, 8.31621170e-01,\n",
       "       9.56959844e-01, 9.95863199e-01, 0.00000000e+00, 1.08182430e-05,\n",
       "       6.28232956e-04, 3.51101160e-04, 9.97823119e-01, 2.62260437e-06,\n",
       "       4.99066710e-03, 9.97210503e-01, 4.47034836e-06, 9.57186580e-01,\n",
       "       7.56236911e-03, 1.43771470e-02, 9.66294944e-01, 6.85453415e-07,\n",
       "       9.31400239e-01, 3.45706940e-05, 9.85006690e-01, 4.35203314e-04,\n",
       "       1.94132328e-04, 9.25992131e-01, 3.31103802e-05, 5.37931919e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.19626081e-01, 2.53915787e-05,\n",
       "       0.00000000e+00, 3.90142202e-04, 9.96864617e-01, 1.47521496e-05,\n",
       "       3.59749854e-01, 1.34608269e-01, 1.60305202e-02, 6.79641962e-04,\n",
       "       7.18235970e-06, 7.96158791e-01, 5.76247275e-01, 1.12775862e-02,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.03319573e-01, 6.18610680e-02,\n",
       "       1.15886003e-01, 0.00000000e+00, 5.66244125e-07, 3.57627869e-07,\n",
       "       1.96695328e-05, 2.25305557e-05, 1.65504217e-03, 5.81145287e-05,\n",
       "       9.87353921e-01, 5.68822026e-03, 9.98459220e-01, 9.01363671e-01,\n",
       "       8.67247581e-06, 4.76818502e-01, 5.52082062e-03, 7.59065151e-05,\n",
       "       1.78813934e-07, 4.03821468e-05, 1.12354755e-05, 1.54972076e-06,\n",
       "       2.59296000e-02, 1.24976635e-01, 9.74801719e-01, 4.01741266e-03,\n",
       "       2.98023224e-08, 1.72853470e-06, 5.00470400e-04, 7.72061944e-03,\n",
       "       3.46935987e-02, 1.72853470e-06, 7.74860382e-07, 3.19135308e-01,\n",
       "       9.76937532e-01, 0.00000000e+00, 1.78813934e-07, 1.87240541e-01,\n",
       "       9.22110915e-01, 2.30759382e-03, 2.84854472e-02, 1.56998634e-01,\n",
       "       9.12818074e-01, 5.78771830e-02, 9.90947604e-01, 2.42471695e-04,\n",
       "       9.59753990e-04, 0.00000000e+00, 4.65900600e-02, 3.96265090e-01,\n",
       "       1.02154315e-02, 5.85668445e-01, 9.86371160e-01, 9.36198115e-01,\n",
       "       0.00000000e+00, 2.19494104e-04, 1.29520893e-04, 1.37627125e-04,\n",
       "       1.78813934e-07, 1.73926353e-04, 8.48513961e-01, 1.00135803e-04,\n",
       "       1.19209290e-07, 1.78766489e-01, 9.90137219e-01, 3.62877250e-02,\n",
       "       3.46389413e-03, 5.15112281e-03, 8.94069672e-07, 9.96365905e-01,\n",
       "       9.11625087e-01, 4.39890173e-05], dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
