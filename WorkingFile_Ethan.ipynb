{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''Sample script for solar array image classification\n",
    "\n",
    "Author:       Kyle Bradbury\n",
    "Date:         January 30, 2018\n",
    "Organization: Duke University Energy Initiative\n",
    "'''\n",
    "\n",
    "'''\n",
    "Import the packages needed for classification\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as metrics\n",
    "plt.close()\n",
    "\n",
    "'''\n",
    "Set directory parameters\n",
    "'''\n",
    "# Set the directories for the data and the CSV files that contain ids/labels\n",
    "dir_train_images  = './data/training/'\n",
    "dir_test_images   = './data/testing/'\n",
    "dir_train_labels  = './data/labels_training.csv'\n",
    "dir_test_ids      = './data/sample_submission.csv'\n",
    "\n",
    "'''\n",
    "Include the functions used for loading, preprocessing, features extraction, \n",
    "classification, and performance evaluation\n",
    "'''\n",
    "\n",
    "def load_data(dir_data, dir_labels, training=True):\n",
    "    '''\n",
    "    Load each of the image files into memory \n",
    "\n",
    "    While this is feasible with a smaller dataset, for larger datasets,\n",
    "    not all the images would be able to be loaded into memory\n",
    "\n",
    "    When training=True, the labels are also loaded\n",
    "    '''\n",
    "    labels_pd = pd.read_csv(dir_labels)\n",
    "    ids       = labels_pd.id.values\n",
    "    data      = []\n",
    "    for identifier in ids:\n",
    "        fname     = dir_data + identifier.astype(str) + '.tif'\n",
    "        image     = mpl.image.imread(fname)\n",
    "        data.append(image)\n",
    "    data = np.array(data) # Convert to Numpy array\n",
    "    if training:\n",
    "        labels = labels_pd.label.values\n",
    "        return data, labels\n",
    "    else:\n",
    "        return data, ids\n",
    "\n",
    "def preprocess_and_extract_features(data):\n",
    "    '''\n",
    "    Preprocess data and extract features\n",
    "    \n",
    "    Preprocess: normalize, scale, repair\n",
    "    Extract features: transformations and dimensionality reduction\n",
    "    '''\n",
    "    # Here, we do something trivially simple: we take the average of the RGB\n",
    "    # values to produce a grey image, transform that into a vector, then\n",
    "    # extract the mean and standard deviation as features.\n",
    "    \n",
    "    # Make the image grayscale\n",
    "    data = np.mean(data, axis=3)\n",
    "    \n",
    "    # Vectorize the grayscale matrices\n",
    "    vectorized_data = data.reshape(data.shape[0],-1)\n",
    "    \n",
    "    # extract the mean and standard deviation of each sample as features\n",
    "    feature_mean = np.mean(vectorized_data,axis=1)\n",
    "    feature_std  = np.std(vectorized_data,axis=1)\n",
    "    \n",
    "    # Combine the extracted features into a single feature vector\n",
    "    features = np.stack((feature_mean,feature_std),axis=-1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def set_classifier():\n",
    "    '''Shared function to select the classifier for both performance evaluation\n",
    "    and testing\n",
    "    '''\n",
    "    return KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "def cv_performance_assessment(X,y,k,clf):\n",
    "    '''\n",
    "    Cross validated performance assessment\n",
    "    \n",
    "    X   = training data\n",
    "    y   = training labels\n",
    "    k   = number of folds for cross validation\n",
    "    clf = classifier to use\n",
    "    \n",
    "    Divide the training data into k folds of training and validation data. \n",
    "    For each fold the classifier will be trained on the training data and\n",
    "    tested on the validation data. The classifier prediction scores are \n",
    "    aggregated and output\n",
    "    '''\n",
    "    # Establish the k folds\n",
    "    prediction_scores = np.empty(y.shape[0],dtype='object')\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "    for train_index, val_index in kf.split(X, y):\n",
    "        # Extract the training and validation data for this fold\n",
    "        X_train, X_val   = X[train_index], X[val_index]\n",
    "        y_train          = y[train_index]\n",
    "        \n",
    "        # Train the classifier\n",
    "        X_train_features = preprocess_and_extract_features(X_train)\n",
    "        clf              = clf.fit(X_train_features,y_train)\n",
    "        \n",
    "        # Test the classifier on the validation data for this fold\n",
    "        X_val_features   = preprocess_and_extract_features(X_val)\n",
    "        cpred            = clf.predict_proba(X_val_features)\n",
    "        \n",
    "        # Save the predictions for this fold\n",
    "        prediction_scores[val_index] = cpred[:,1]\n",
    "    return prediction_scores\n",
    "\n",
    "def plot_roc(labels, prediction_scores):\n",
    "    '''\n",
    "    Draw roc curve with pyplot.\n",
    "    \n",
    "    labels = actual labels of the data being predicted, for comparison.\n",
    "    prediction_scores = predicted probabilities of containing a solar panel\n",
    "    '''\n",
    "    \n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, prediction_scores, pos_label=1)\n",
    "    auc = metrics.roc_auc_score(labels, prediction_scores)\n",
    "    legend_string = 'AUC = {:0.3f}'.format(auc)\n",
    "   \n",
    "    plt.plot([0,1],[0,1],'--', color='gray', label='Chance')\n",
    "    plt.plot(fpr, tpr, label=legend_string)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.grid('on')\n",
    "    plt.axis('square')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "'''\n",
    "Sample script for cross validated performance\n",
    "'''\n",
    "\n",
    "'''\n",
    "# Set parameters for the analysis\n",
    "num_training_folds = 20\n",
    "\n",
    "# Load the data\n",
    "\n",
    "# Choose which classifier to use\n",
    "clf = set_classifier()\n",
    "\n",
    "# Perform cross validated performance assessment\n",
    "prediction_scores = cv_performance_assessment(data,labels,num_training_folds,clf)\n",
    "\n",
    "# Compute and plot the ROC curves\n",
    "plot_roc(labels, prediction_scores)\n",
    "'''\n",
    "\n",
    "'''\n",
    "Function for producing a Kaggle submission\n",
    "'''\n",
    "def produce_submission(fileName):\n",
    "    # Load data, extract features, and train the classifier on the training data\n",
    "    training_data, training_labels = load_data(dir_train_images, dir_train_labels, training=True)\n",
    "    training_features              = preprocess_and_extract_features(training_data)\n",
    "    clf                            = set_classifier()\n",
    "    clf.fit(training_features,training_labels)\n",
    "\n",
    "    # Load the test data and test the classifier\n",
    "    test_data, ids = load_data(dir_test_images, dir_test_ids, training=False)\n",
    "    test_features  = preprocess_and_extract_features(test_data)\n",
    "    test_scores    = clf.predict_proba(test_features)[:,1]\n",
    "\n",
    "    # Save the predictions to a CSV file for upload to Kaggle\n",
    "    submission_file = pd.DataFrame({'id':    ids,\n",
    "                                   'score':  test_scores})\n",
    "    submission_file.to_csv(fileName, columns=['id','score'], index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_submission(\"ethan_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
