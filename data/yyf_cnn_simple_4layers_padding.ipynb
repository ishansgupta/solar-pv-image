{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.close()\n",
    "\n",
    "# Set the directories for the data and the CSV files that contain ids/labels\n",
    "dir_train_images  = './training/'\n",
    "dir_test_images   = './testing/'\n",
    "dir_train_labels  = './labels_training.csv'\n",
    "dir_test_ids      = './sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_data, dir_labels, training=True):\n",
    "    ''' Load each of the image files into memory \n",
    "\n",
    "    While this is feasible with a smaller dataset, for larger datasets,\n",
    "    not all the images would be able to be loaded into memory\n",
    "\n",
    "    When training=True, the labels are also loaded\n",
    "    '''\n",
    "    labels_pd = pd.read_csv(dir_labels)\n",
    "    ids       = labels_pd.id.values\n",
    "    data      = []\n",
    "    for identifier in ids:\n",
    "        fname     = dir_data + identifier.astype(str) + '.tif'\n",
    "        image     = mpl.image.imread(fname)\n",
    "        data.append(image)\n",
    "    data = np.array(data) # Convert to Numpy array\n",
    "    if training:\n",
    "        labels = labels_pd.label.values\n",
    "        return data, labels\n",
    "    else:\n",
    "        return data, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, y_binary = load_data(dir_train_images, dir_train_labels, training=True)\n",
    "\n",
    "test_data, ids = load_data(dir_test_images, dir_test_ids, training=False)\n",
    "\n",
    "img_rows, img_cols = 101, 101\n",
    "\n",
    "data = data.astype('float32')\n",
    "data /= 255\n",
    "\n",
    "test_data = test_data.astype('float32')\n",
    "test_data /= 255\n",
    "\n",
    "input_shape = img_rows, img_cols, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, train_label, validation_label = train_test_split(data, y_binary, test_size=100, random_state=114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = input_shape, activation = 'relu', padding = 'same'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "#classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#classifier.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
    "#classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#classifier.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third convolutional layer\n",
    "classifier.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
    "#classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "# Adding a fourth convolutional layer\n",
    "classifier.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
    "#classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#classifier.add(Dropout(0.2))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 64, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(loss=keras.losses.binary_crossentropy,\n",
    "          optimizer=keras.optimizers.Adam(),\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 101, 101, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 535,873\n",
      "Trainable params: 535,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 100 samples\n",
      "Epoch 1/40\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.6945 - accuracy: 0.5953 - val_loss: 0.6702 - val_accuracy: 0.6200\n",
      "Epoch 2/40\n",
      "1500/1500 [==============================] - 1s 853us/step - loss: 0.6484 - accuracy: 0.6633 - val_loss: 0.6699 - val_accuracy: 0.6200\n",
      "Epoch 3/40\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.6505 - accuracy: 0.6633 - val_loss: 0.6704 - val_accuracy: 0.6200\n",
      "Epoch 4/40\n",
      "1500/1500 [==============================] - 1s 865us/step - loss: 0.6421 - accuracy: 0.6633 - val_loss: 0.6677 - val_accuracy: 0.6200\n",
      "Epoch 5/40\n",
      "1500/1500 [==============================] - 1s 860us/step - loss: 0.6441 - accuracy: 0.6633 - val_loss: 0.6734 - val_accuracy: 0.6200\n",
      "Epoch 6/40\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.6411 - accuracy: 0.6633 - val_loss: 0.6656 - val_accuracy: 0.6200\n",
      "Epoch 7/40\n",
      "1500/1500 [==============================] - 1s 853us/step - loss: 0.6388 - accuracy: 0.6633 - val_loss: 0.6625 - val_accuracy: 0.6200\n",
      "Epoch 8/40\n",
      "1500/1500 [==============================] - 1s 860us/step - loss: 0.6380 - accuracy: 0.6633 - val_loss: 0.6618 - val_accuracy: 0.6200\n",
      "Epoch 9/40\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.6359 - accuracy: 0.6633 - val_loss: 0.6554 - val_accuracy: 0.6200\n",
      "Epoch 10/40\n",
      "1500/1500 [==============================] - 1s 865us/step - loss: 0.6142 - accuracy: 0.6633 - val_loss: 0.8034 - val_accuracy: 0.6200\n",
      "Epoch 11/40\n",
      "1500/1500 [==============================] - 1s 869us/step - loss: 0.6475 - accuracy: 0.6700 - val_loss: 0.6519 - val_accuracy: 0.6200\n",
      "Epoch 12/40\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.6208 - accuracy: 0.6633 - val_loss: 0.6331 - val_accuracy: 0.6200\n",
      "Epoch 13/40\n",
      "1500/1500 [==============================] - 1s 875us/step - loss: 0.6000 - accuracy: 0.6640 - val_loss: 0.6223 - val_accuracy: 0.6100\n",
      "Epoch 14/40\n",
      "1500/1500 [==============================] - 1s 845us/step - loss: 0.6313 - accuracy: 0.6787 - val_loss: 0.6402 - val_accuracy: 0.6200\n",
      "Epoch 15/40\n",
      "1500/1500 [==============================] - 1s 975us/step - loss: 0.5823 - accuracy: 0.6873 - val_loss: 0.6581 - val_accuracy: 0.6600\n",
      "Epoch 16/40\n",
      "1500/1500 [==============================] - 1s 897us/step - loss: 0.5741 - accuracy: 0.6933 - val_loss: 0.6276 - val_accuracy: 0.6500\n",
      "Epoch 17/40\n",
      "1500/1500 [==============================] - 1s 868us/step - loss: 0.5638 - accuracy: 0.7080 - val_loss: 0.5804 - val_accuracy: 0.7000\n",
      "Epoch 18/40\n",
      "1500/1500 [==============================] - 1s 860us/step - loss: 0.5728 - accuracy: 0.6967 - val_loss: 0.5861 - val_accuracy: 0.7200\n",
      "Epoch 19/40\n",
      "1500/1500 [==============================] - 1s 865us/step - loss: 0.5414 - accuracy: 0.7287 - val_loss: 0.5583 - val_accuracy: 0.7000\n",
      "Epoch 20/40\n",
      "1500/1500 [==============================] - 1s 857us/step - loss: 0.5394 - accuracy: 0.7293 - val_loss: 0.5529 - val_accuracy: 0.7400\n",
      "Epoch 21/40\n",
      "1500/1500 [==============================] - 1s 862us/step - loss: 0.5272 - accuracy: 0.7433 - val_loss: 0.5451 - val_accuracy: 0.7900\n",
      "Epoch 22/40\n",
      "1500/1500 [==============================] - 1s 865us/step - loss: 0.5030 - accuracy: 0.7560 - val_loss: 0.5407 - val_accuracy: 0.7700\n",
      "Epoch 23/40\n",
      "1500/1500 [==============================] - 1s 866us/step - loss: 0.4789 - accuracy: 0.7580 - val_loss: 0.5239 - val_accuracy: 0.7800\n",
      "Epoch 24/40\n",
      "1500/1500 [==============================] - 1s 884us/step - loss: 0.5132 - accuracy: 0.7547 - val_loss: 0.5607 - val_accuracy: 0.8100\n",
      "Epoch 25/40\n",
      "1500/1500 [==============================] - 1s 868us/step - loss: 0.4865 - accuracy: 0.7680 - val_loss: 0.5179 - val_accuracy: 0.7600\n",
      "Epoch 26/40\n",
      "1500/1500 [==============================] - 1s 865us/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4528 - val_accuracy: 0.8000\n",
      "Epoch 27/40\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.4033 - accuracy: 0.8193 - val_loss: 0.4050 - val_accuracy: 0.8100\n",
      "Epoch 28/40\n",
      "1500/1500 [==============================] - 1s 862us/step - loss: 0.3960 - accuracy: 0.8280 - val_loss: 0.3953 - val_accuracy: 0.8500\n",
      "Epoch 29/40\n",
      "1500/1500 [==============================] - 1s 870us/step - loss: 0.3570 - accuracy: 0.8440 - val_loss: 0.3825 - val_accuracy: 0.8600\n",
      "Epoch 30/40\n",
      "1500/1500 [==============================] - 1s 868us/step - loss: 0.3712 - accuracy: 0.8400 - val_loss: 0.3913 - val_accuracy: 0.8700\n",
      "Epoch 31/40\n",
      "1500/1500 [==============================] - 1s 864us/step - loss: 0.2907 - accuracy: 0.8833 - val_loss: 0.2624 - val_accuracy: 0.9000\n",
      "Epoch 32/40\n",
      "1500/1500 [==============================] - 1s 867us/step - loss: 0.2918 - accuracy: 0.8713 - val_loss: 0.3206 - val_accuracy: 0.8400\n",
      "Epoch 33/40\n",
      "1500/1500 [==============================] - 1s 879us/step - loss: 0.3319 - accuracy: 0.8513 - val_loss: 0.2701 - val_accuracy: 0.8600\n",
      "Epoch 34/40\n",
      "1500/1500 [==============================] - 1s 861us/step - loss: 0.2470 - accuracy: 0.9000 - val_loss: 0.2542 - val_accuracy: 0.8900\n",
      "Epoch 35/40\n",
      "1500/1500 [==============================] - 1s 870us/step - loss: 0.3296 - accuracy: 0.8587 - val_loss: 0.3360 - val_accuracy: 0.9000\n",
      "Epoch 36/40\n",
      "1500/1500 [==============================] - 1s 868us/step - loss: 0.3191 - accuracy: 0.8553 - val_loss: 0.2706 - val_accuracy: 0.8900\n",
      "Epoch 37/40\n",
      "1500/1500 [==============================] - 1s 867us/step - loss: 0.2455 - accuracy: 0.9007 - val_loss: 0.2305 - val_accuracy: 0.9300\n",
      "Epoch 38/40\n",
      "1500/1500 [==============================] - 1s 868us/step - loss: 0.1914 - accuracy: 0.9313 - val_loss: 0.1700 - val_accuracy: 0.9300\n",
      "Epoch 39/40\n",
      "1500/1500 [==============================] - 1s 863us/step - loss: 0.2040 - accuracy: 0.9133 - val_loss: 0.1691 - val_accuracy: 0.9500\n",
      "Epoch 40/40\n",
      "1500/1500 [==============================] - 1s 863us/step - loss: 0.1844 - accuracy: 0.9233 - val_loss: 0.2126 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "history4 = classifier.fit(\n",
    "    data, \n",
    "    y_binary,\n",
    "    batch_size=100,\n",
    "    epochs=40,\n",
    "    verbose=1,\n",
    "    validation_data=(validation_data, validation_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "15/15 [==============================] - 3s 182ms/step - loss: 0.4431 - accuracy: 0.8193 - val_loss: 0.3496 - val_accuracy: 0.8600\n",
      "Epoch 2/150\n",
      "15/15 [==============================] - 3s 185ms/step - loss: 0.3394 - accuracy: 0.8607 - val_loss: 0.3510 - val_accuracy: 0.8400\n",
      "Epoch 3/150\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 0.3454 - accuracy: 0.8540 - val_loss: 0.2856 - val_accuracy: 0.9000\n",
      "Epoch 4/150\n",
      "15/15 [==============================] - 3s 190ms/step - loss: 0.3098 - accuracy: 0.8780 - val_loss: 0.2902 - val_accuracy: 0.8600\n",
      "Epoch 5/150\n",
      "15/15 [==============================] - 3s 187ms/step - loss: 0.2691 - accuracy: 0.8953 - val_loss: 0.3108 - val_accuracy: 0.8300\n",
      "Epoch 6/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.3733 - accuracy: 0.8333 - val_loss: 0.4083 - val_accuracy: 0.8500\n",
      "Epoch 7/150\n",
      "15/15 [==============================] - 3s 203ms/step - loss: 0.3068 - accuracy: 0.8860 - val_loss: 0.2909 - val_accuracy: 0.8900\n",
      "Epoch 8/150\n",
      "15/15 [==============================] - 3s 209ms/step - loss: 0.2776 - accuracy: 0.8927 - val_loss: 0.2828 - val_accuracy: 0.9000\n",
      "Epoch 9/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.2536 - accuracy: 0.8980 - val_loss: 0.2671 - val_accuracy: 0.8600\n",
      "Epoch 10/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.2202 - accuracy: 0.9127 - val_loss: 0.2139 - val_accuracy: 0.9300\n",
      "Epoch 11/150\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.2046 - accuracy: 0.9293 - val_loss: 0.2276 - val_accuracy: 0.9000\n",
      "Epoch 12/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.2133 - accuracy: 0.9187 - val_loss: 0.1974 - val_accuracy: 0.9300\n",
      "Epoch 13/150\n",
      "15/15 [==============================] - 3s 207ms/step - loss: 0.2131 - accuracy: 0.9247 - val_loss: 0.2013 - val_accuracy: 0.9100\n",
      "Epoch 14/150\n",
      "15/15 [==============================] - 3s 202ms/step - loss: 0.1996 - accuracy: 0.9280 - val_loss: 0.2133 - val_accuracy: 0.8900\n",
      "Epoch 15/150\n",
      "15/15 [==============================] - 3s 206ms/step - loss: 0.1914 - accuracy: 0.9293 - val_loss: 0.2012 - val_accuracy: 0.9300\n",
      "Epoch 16/150\n",
      "15/15 [==============================] - 3s 203ms/step - loss: 0.1763 - accuracy: 0.9320 - val_loss: 0.1256 - val_accuracy: 0.9500\n",
      "Epoch 17/150\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.1910 - accuracy: 0.9313 - val_loss: 0.1994 - val_accuracy: 0.9100\n",
      "Epoch 18/150\n",
      "15/15 [==============================] - 3s 202ms/step - loss: 0.2532 - accuracy: 0.8967 - val_loss: 0.2912 - val_accuracy: 0.8500\n",
      "Epoch 19/150\n",
      "15/15 [==============================] - 3s 204ms/step - loss: 0.2362 - accuracy: 0.9107 - val_loss: 0.2205 - val_accuracy: 0.9000\n",
      "Epoch 20/150\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.1625 - accuracy: 0.9393 - val_loss: 0.2050 - val_accuracy: 0.9200\n",
      "Epoch 21/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.1867 - accuracy: 0.9327 - val_loss: 0.1793 - val_accuracy: 0.9300\n",
      "Epoch 22/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.1905 - accuracy: 0.9300 - val_loss: 0.2010 - val_accuracy: 0.9100\n",
      "Epoch 23/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.1633 - accuracy: 0.9407 - val_loss: 0.1705 - val_accuracy: 0.9500\n",
      "Epoch 24/150\n",
      "15/15 [==============================] - 3s 211ms/step - loss: 0.1622 - accuracy: 0.9393 - val_loss: 0.1579 - val_accuracy: 0.9600\n",
      "Epoch 25/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.1635 - accuracy: 0.9380 - val_loss: 0.1685 - val_accuracy: 0.9400\n",
      "Epoch 26/150\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.1807 - accuracy: 0.9333 - val_loss: 0.2166 - val_accuracy: 0.9500\n",
      "Epoch 27/150\n",
      "15/15 [==============================] - 3s 208ms/step - loss: 0.1922 - accuracy: 0.9233 - val_loss: 0.2141 - val_accuracy: 0.9000\n",
      "Epoch 28/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.1491 - accuracy: 0.9473 - val_loss: 0.1268 - val_accuracy: 0.9700\n",
      "Epoch 29/150\n",
      "15/15 [==============================] - 3s 208ms/step - loss: 0.1954 - accuracy: 0.9327 - val_loss: 0.1550 - val_accuracy: 0.9600\n",
      "Epoch 30/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.1619 - accuracy: 0.9333 - val_loss: 0.1910 - val_accuracy: 0.9500\n",
      "Epoch 31/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.1331 - accuracy: 0.9507 - val_loss: 0.2000 - val_accuracy: 0.9200\n",
      "Epoch 32/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.1854 - accuracy: 0.9313 - val_loss: 0.1624 - val_accuracy: 0.9200\n",
      "Epoch 33/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.1570 - accuracy: 0.9433 - val_loss: 0.1852 - val_accuracy: 0.9200\n",
      "Epoch 34/150\n",
      "15/15 [==============================] - 3s 211ms/step - loss: 0.1552 - accuracy: 0.9440 - val_loss: 0.1596 - val_accuracy: 0.9200\n",
      "Epoch 35/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.1833 - accuracy: 0.9293 - val_loss: 0.1634 - val_accuracy: 0.9200\n",
      "Epoch 36/150\n",
      "15/15 [==============================] - 3s 202ms/step - loss: 0.1690 - accuracy: 0.9347 - val_loss: 0.2043 - val_accuracy: 0.9200\n",
      "Epoch 37/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.1520 - accuracy: 0.9407 - val_loss: 0.1719 - val_accuracy: 0.9500\n",
      "Epoch 38/150\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.1357 - accuracy: 0.9547 - val_loss: 0.1227 - val_accuracy: 0.9500\n",
      "Epoch 39/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.1447 - accuracy: 0.9467 - val_loss: 0.1310 - val_accuracy: 0.9300\n",
      "Epoch 40/150\n",
      "15/15 [==============================] - 3s 209ms/step - loss: 0.1405 - accuracy: 0.9500 - val_loss: 0.1122 - val_accuracy: 0.9600\n",
      "Epoch 41/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.1369 - accuracy: 0.9540 - val_loss: 0.1542 - val_accuracy: 0.9300\n",
      "Epoch 42/150\n",
      "15/15 [==============================] - 3s 224ms/step - loss: 0.1248 - accuracy: 0.9513 - val_loss: 0.0995 - val_accuracy: 0.9600\n",
      "Epoch 43/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.1263 - accuracy: 0.9540 - val_loss: 0.0831 - val_accuracy: 0.9700\n",
      "Epoch 44/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.1316 - accuracy: 0.9533 - val_loss: 0.1121 - val_accuracy: 0.9600\n",
      "Epoch 45/150\n",
      "15/15 [==============================] - 3s 211ms/step - loss: 0.1263 - accuracy: 0.9553 - val_loss: 0.1409 - val_accuracy: 0.9400\n",
      "Epoch 46/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.1757 - accuracy: 0.9353 - val_loss: 0.1490 - val_accuracy: 0.9400\n",
      "Epoch 47/150\n",
      "15/15 [==============================] - 3s 202ms/step - loss: 0.1391 - accuracy: 0.9513 - val_loss: 0.1002 - val_accuracy: 0.9800\n",
      "Epoch 48/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.1365 - accuracy: 0.9500 - val_loss: 0.1098 - val_accuracy: 0.9700\n",
      "Epoch 49/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.1104 - accuracy: 0.9620 - val_loss: 0.1223 - val_accuracy: 0.9500\n",
      "Epoch 50/150\n",
      "15/15 [==============================] - 3s 211ms/step - loss: 0.1409 - accuracy: 0.9440 - val_loss: 0.2762 - val_accuracy: 0.9000\n",
      "Epoch 51/150\n",
      "15/15 [==============================] - 3s 207ms/step - loss: 0.1673 - accuracy: 0.9407 - val_loss: 0.1062 - val_accuracy: 0.9700\n",
      "Epoch 52/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.1380 - accuracy: 0.9493 - val_loss: 0.1254 - val_accuracy: 0.9300\n",
      "Epoch 53/150\n",
      "15/15 [==============================] - 3s 203ms/step - loss: 0.1376 - accuracy: 0.9467 - val_loss: 0.1208 - val_accuracy: 0.9500\n",
      "Epoch 54/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.1147 - accuracy: 0.9560 - val_loss: 0.0994 - val_accuracy: 0.9700\n",
      "Epoch 55/150\n",
      "15/15 [==============================] - 3s 208ms/step - loss: 0.1139 - accuracy: 0.9560 - val_loss: 0.1104 - val_accuracy: 0.9500\n",
      "Epoch 56/150\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.1368 - accuracy: 0.9500 - val_loss: 0.1806 - val_accuracy: 0.9300\n",
      "Epoch 57/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.1165 - accuracy: 0.9580 - val_loss: 0.1303 - val_accuracy: 0.9500\n",
      "Epoch 58/150\n",
      "15/15 [==============================] - 3s 202ms/step - loss: 0.1167 - accuracy: 0.9540 - val_loss: 0.0958 - val_accuracy: 0.9800\n",
      "Epoch 59/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.1271 - accuracy: 0.9533 - val_loss: 0.0829 - val_accuracy: 0.9800\n",
      "Epoch 60/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.1225 - accuracy: 0.9507 - val_loss: 0.0823 - val_accuracy: 0.9800\n",
      "Epoch 61/150\n",
      "15/15 [==============================] - 3s 211ms/step - loss: 0.1219 - accuracy: 0.9620 - val_loss: 0.0983 - val_accuracy: 0.9700\n",
      "Epoch 62/150\n",
      "15/15 [==============================] - 3s 196ms/step - loss: 0.1162 - accuracy: 0.9527 - val_loss: 0.1660 - val_accuracy: 0.9200\n",
      "Epoch 63/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.1247 - accuracy: 0.9500 - val_loss: 0.1175 - val_accuracy: 0.9600\n",
      "Epoch 64/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.1065 - accuracy: 0.9587 - val_loss: 0.1203 - val_accuracy: 0.9400\n",
      "Epoch 65/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.1113 - accuracy: 0.9627 - val_loss: 0.0953 - val_accuracy: 0.9500\n",
      "Epoch 66/150\n",
      "15/15 [==============================] - 3s 212ms/step - loss: 0.0960 - accuracy: 0.9693 - val_loss: 0.0908 - val_accuracy: 0.9400\n",
      "Epoch 67/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.1036 - accuracy: 0.9613 - val_loss: 0.1017 - val_accuracy: 0.9700\n",
      "Epoch 68/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.0923 - accuracy: 0.9647 - val_loss: 0.0673 - val_accuracy: 0.9800\n",
      "Epoch 69/150\n",
      "15/15 [==============================] - 3s 205ms/step - loss: 0.0940 - accuracy: 0.9633 - val_loss: 0.1008 - val_accuracy: 0.9600\n",
      "Epoch 70/150\n",
      "15/15 [==============================] - 3s 196ms/step - loss: 0.0867 - accuracy: 0.9733 - val_loss: 0.1174 - val_accuracy: 0.9300\n",
      "Epoch 71/150\n",
      "15/15 [==============================] - 3s 211ms/step - loss: 0.0884 - accuracy: 0.9707 - val_loss: 0.1211 - val_accuracy: 0.9400\n",
      "Epoch 72/150\n",
      "15/15 [==============================] - 3s 205ms/step - loss: 0.1058 - accuracy: 0.9647 - val_loss: 0.0875 - val_accuracy: 0.9800\n",
      "Epoch 73/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.0941 - accuracy: 0.9660 - val_loss: 0.0598 - val_accuracy: 0.9900\n",
      "Epoch 74/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.0870 - accuracy: 0.9687 - val_loss: 0.1005 - val_accuracy: 0.9700\n",
      "Epoch 75/150\n",
      "15/15 [==============================] - 3s 209ms/step - loss: 0.1141 - accuracy: 0.9600 - val_loss: 0.0995 - val_accuracy: 0.9700\n",
      "Epoch 76/150\n",
      "15/15 [==============================] - 4s 235ms/step - loss: 0.1135 - accuracy: 0.9580 - val_loss: 0.1084 - val_accuracy: 0.9600\n",
      "Epoch 77/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.1060 - accuracy: 0.9633 - val_loss: 0.0698 - val_accuracy: 0.9900\n",
      "Epoch 78/150\n",
      "15/15 [==============================] - 3s 217ms/step - loss: 0.1045 - accuracy: 0.9633 - val_loss: 0.0712 - val_accuracy: 0.9700\n",
      "Epoch 79/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.0824 - accuracy: 0.9693 - val_loss: 0.0545 - val_accuracy: 0.9900\n",
      "Epoch 80/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.0771 - accuracy: 0.9660 - val_loss: 0.0547 - val_accuracy: 0.9800\n",
      "Epoch 81/150\n",
      "15/15 [==============================] - 3s 220ms/step - loss: 0.0876 - accuracy: 0.9640 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
      "Epoch 82/150\n",
      "15/15 [==============================] - 3s 203ms/step - loss: 0.0957 - accuracy: 0.9660 - val_loss: 0.0976 - val_accuracy: 0.9700\n",
      "Epoch 83/150\n",
      "15/15 [==============================] - 3s 211ms/step - loss: 0.0968 - accuracy: 0.9647 - val_loss: 0.0824 - val_accuracy: 0.9600\n",
      "Epoch 84/150\n",
      "15/15 [==============================] - 3s 207ms/step - loss: 0.0825 - accuracy: 0.9700 - val_loss: 0.0478 - val_accuracy: 0.9900\n",
      "Epoch 85/150\n",
      "15/15 [==============================] - 3s 205ms/step - loss: 0.0850 - accuracy: 0.9693 - val_loss: 0.0899 - val_accuracy: 0.9800\n",
      "Epoch 86/150\n",
      "15/15 [==============================] - 3s 203ms/step - loss: 0.0854 - accuracy: 0.9740 - val_loss: 0.0947 - val_accuracy: 0.9500\n",
      "Epoch 87/150\n",
      "15/15 [==============================] - 3s 205ms/step - loss: 0.0774 - accuracy: 0.9720 - val_loss: 0.0790 - val_accuracy: 0.9600\n",
      "Epoch 88/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.0876 - accuracy: 0.9647 - val_loss: 0.0898 - val_accuracy: 0.9800\n",
      "Epoch 89/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.0998 - accuracy: 0.9620 - val_loss: 0.0865 - val_accuracy: 0.9700\n",
      "Epoch 90/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.0742 - accuracy: 0.9733 - val_loss: 0.0613 - val_accuracy: 0.9900\n",
      "Epoch 91/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.0725 - accuracy: 0.9713 - val_loss: 0.0395 - val_accuracy: 0.9900\n",
      "Epoch 92/150\n",
      "15/15 [==============================] - 3s 213ms/step - loss: 0.1075 - accuracy: 0.9573 - val_loss: 0.0961 - val_accuracy: 0.9900\n",
      "Epoch 93/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.0959 - accuracy: 0.9653 - val_loss: 0.1118 - val_accuracy: 0.9700\n",
      "Epoch 94/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.1072 - accuracy: 0.9560 - val_loss: 0.1178 - val_accuracy: 0.9500\n",
      "Epoch 95/150\n",
      "15/15 [==============================] - 3s 205ms/step - loss: 0.0945 - accuracy: 0.9653 - val_loss: 0.0746 - val_accuracy: 0.9700\n",
      "Epoch 96/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.0829 - accuracy: 0.9713 - val_loss: 0.0582 - val_accuracy: 0.9900\n",
      "Epoch 97/150\n",
      "15/15 [==============================] - 3s 208ms/step - loss: 0.0596 - accuracy: 0.9780 - val_loss: 0.0744 - val_accuracy: 0.9800\n",
      "Epoch 98/150\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.0585 - accuracy: 0.9807 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "15/15 [==============================] - 3s 202ms/step - loss: 0.0749 - accuracy: 0.9713 - val_loss: 0.0581 - val_accuracy: 0.9800\n",
      "Epoch 100/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.0652 - accuracy: 0.9760 - val_loss: 0.0729 - val_accuracy: 0.9700\n",
      "Epoch 101/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0646 - accuracy: 0.9773 - val_loss: 0.0725 - val_accuracy: 0.9500\n",
      "Epoch 102/150\n",
      "15/15 [==============================] - 3s 205ms/step - loss: 0.0880 - accuracy: 0.9687 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "15/15 [==============================] - 3s 208ms/step - loss: 0.0759 - accuracy: 0.9720 - val_loss: 0.0372 - val_accuracy: 0.9900\n",
      "Epoch 104/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.0698 - accuracy: 0.9720 - val_loss: 0.0523 - val_accuracy: 0.9900\n",
      "Epoch 105/150\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.0824 - accuracy: 0.9707 - val_loss: 0.0404 - val_accuracy: 0.9800\n",
      "Epoch 106/150\n",
      "15/15 [==============================] - 3s 202ms/step - loss: 0.0741 - accuracy: 0.9733 - val_loss: 0.0621 - val_accuracy: 0.9800\n",
      "Epoch 107/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0747 - accuracy: 0.9747 - val_loss: 0.0577 - val_accuracy: 0.9800\n",
      "Epoch 108/150\n",
      "15/15 [==============================] - 3s 214ms/step - loss: 0.0672 - accuracy: 0.9760 - val_loss: 0.0697 - val_accuracy: 0.9700\n",
      "Epoch 109/150\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.0623 - accuracy: 0.9747 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.0649 - accuracy: 0.9793 - val_loss: 0.0664 - val_accuracy: 0.9700\n",
      "Epoch 111/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0698 - accuracy: 0.9760 - val_loss: 0.0618 - val_accuracy: 0.9700\n",
      "Epoch 112/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.0530 - accuracy: 0.9807 - val_loss: 0.0752 - val_accuracy: 0.9900\n",
      "Epoch 113/150\n",
      "15/15 [==============================] - 3s 208ms/step - loss: 0.0731 - accuracy: 0.9733 - val_loss: 0.0520 - val_accuracy: 0.9900\n",
      "Epoch 114/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.0882 - accuracy: 0.9653 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "15/15 [==============================] - 3s 204ms/step - loss: 0.0690 - accuracy: 0.9747 - val_loss: 0.0642 - val_accuracy: 0.9800\n",
      "Epoch 116/150\n",
      "15/15 [==============================] - 3s 204ms/step - loss: 0.0733 - accuracy: 0.9727 - val_loss: 0.0730 - val_accuracy: 0.9700\n",
      "Epoch 117/150\n",
      "15/15 [==============================] - 3s 207ms/step - loss: 0.1311 - accuracy: 0.9533 - val_loss: 0.0492 - val_accuracy: 0.9900\n",
      "Epoch 118/150\n",
      "15/15 [==============================] - 3s 210ms/step - loss: 0.0686 - accuracy: 0.9780 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.0657 - accuracy: 0.9780 - val_loss: 0.0754 - val_accuracy: 0.9800\n",
      "Epoch 120/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.0760 - accuracy: 0.9693 - val_loss: 0.0201 - val_accuracy: 0.9900\n",
      "Epoch 121/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.0888 - accuracy: 0.9680 - val_loss: 0.0865 - val_accuracy: 0.9700\n",
      "Epoch 122/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0872 - accuracy: 0.9680 - val_loss: 0.0670 - val_accuracy: 0.9900\n",
      "Epoch 123/150\n",
      "15/15 [==============================] - 3s 205ms/step - loss: 0.0618 - accuracy: 0.9807 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
      "Epoch 124/150\n",
      "15/15 [==============================] - 3s 207ms/step - loss: 0.0771 - accuracy: 0.9740 - val_loss: 0.0528 - val_accuracy: 0.9800\n",
      "Epoch 125/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0915 - accuracy: 0.9667 - val_loss: 0.0769 - val_accuracy: 0.9700\n",
      "Epoch 126/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0798 - accuracy: 0.9727 - val_loss: 0.0529 - val_accuracy: 0.9800\n",
      "Epoch 127/150\n",
      "15/15 [==============================] - 3s 204ms/step - loss: 0.0594 - accuracy: 0.9787 - val_loss: 0.0419 - val_accuracy: 0.9900\n",
      "Epoch 128/150\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.0551 - accuracy: 0.9787 - val_loss: 0.0380 - val_accuracy: 0.9900\n",
      "Epoch 129/150\n",
      "15/15 [==============================] - 3s 208ms/step - loss: 0.0567 - accuracy: 0.9813 - val_loss: 0.0493 - val_accuracy: 0.9900\n",
      "Epoch 130/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0496 - accuracy: 0.9820 - val_loss: 0.0377 - val_accuracy: 0.9900\n",
      "Epoch 131/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 0.0381 - val_accuracy: 0.9800\n",
      "Epoch 132/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.0575 - accuracy: 0.9787 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.0648 - accuracy: 0.9740 - val_loss: 0.0419 - val_accuracy: 0.9900\n",
      "Epoch 134/150\n",
      "15/15 [==============================] - 3s 218ms/step - loss: 0.0589 - accuracy: 0.9820 - val_loss: 0.0637 - val_accuracy: 0.9700\n",
      "Epoch 135/150\n",
      "15/15 [==============================] - 3s 197ms/step - loss: 0.0467 - accuracy: 0.9827 - val_loss: 0.0410 - val_accuracy: 0.9900\n",
      "Epoch 136/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.0403 - accuracy: 0.9867 - val_loss: 0.0623 - val_accuracy: 0.9800\n",
      "Epoch 137/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.0880 - accuracy: 0.9667 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0681 - accuracy: 0.9720 - val_loss: 0.0486 - val_accuracy: 0.9900\n",
      "Epoch 139/150\n",
      "15/15 [==============================] - 3s 209ms/step - loss: 0.0607 - accuracy: 0.9853 - val_loss: 0.0219 - val_accuracy: 0.9900\n",
      "Epoch 140/150\n",
      "15/15 [==============================] - 3s 205ms/step - loss: 0.0527 - accuracy: 0.9793 - val_loss: 0.0454 - val_accuracy: 0.9800\n",
      "Epoch 141/150\n",
      "15/15 [==============================] - 3s 208ms/step - loss: 0.0659 - accuracy: 0.9780 - val_loss: 0.0618 - val_accuracy: 0.9600\n",
      "Epoch 142/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0616 - accuracy: 0.9787 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.0643 - accuracy: 0.9787 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "15/15 [==============================] - 3s 202ms/step - loss: 0.0505 - accuracy: 0.9800 - val_loss: 0.0654 - val_accuracy: 0.9800\n",
      "Epoch 145/150\n",
      "15/15 [==============================] - 3s 208ms/step - loss: 0.0500 - accuracy: 0.9827 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.0531 - accuracy: 0.9807 - val_loss: 0.0655 - val_accuracy: 0.9700\n",
      "Epoch 147/150\n",
      "15/15 [==============================] - 3s 200ms/step - loss: 0.0580 - accuracy: 0.9760 - val_loss: 0.0964 - val_accuracy: 0.9700\n",
      "Epoch 148/150\n",
      "15/15 [==============================] - 3s 198ms/step - loss: 0.0934 - accuracy: 0.9680 - val_loss: 0.0672 - val_accuracy: 0.9800\n",
      "Epoch 149/150\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.0882 - accuracy: 0.9633 - val_loss: 0.0741 - val_accuracy: 0.9500\n",
      "Epoch 150/150\n",
      "15/15 [==============================] - 3s 207ms/step - loss: 0.0990 - accuracy: 0.9593 - val_loss: 0.0412 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "gen = ImageDataGenerator(rotation_range=90, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "batches = gen.flow(data, y_binary, batch_size=100)\n",
    "validation_batches = gen.flow(validation_data, validation_label, batch_size=100)\n",
    "\n",
    "history4 = classifier.fit_generator(batches, epochs=150, validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas\n",
    "import numpy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(labels, prediction_scores, title='ROC'):\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, prediction_scores, pos_label=1)\n",
    "    auc = metrics.roc_auc_score(labels, prediction_scores)\n",
    "    legend_string = 'AUC = {:0.3f}'.format(auc)\n",
    "       \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot([0,1],[0,1],'--', color='gray', label='Chance')\n",
    "    plt.plot(fpr, tpr, label=legend_string, color = 'red')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.grid()\n",
    "    plt.axis('square')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = classifier.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAI4CAYAAABNxWJZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeZhV5Znu//uhqIEZGWWUWZChSmQSUQsVHDKoadt2aI1GRJJWTzrnXEdPJ3063Ul359j969g5SQfQ2Go7YMeo0fwcQKXQKAg4IJMKiEgBAoKFFGNV8Zw/9t70ZlvDLqrWWnv4fq6rLmuvvWrvp15K6uZ9n3ctc3cBAABkgzZRFwAAAJAuggsAAMgaBBcAAJA1CC4AACBrEFwAAEDWILgAAICsQXABAABZg+ACIHRm9omZHTKzajP7zMweNLOOSc9PNbNXzWy/me0zs+fM7IyU1+hsZvea2afx19kYf9wj/O8IQFgILgCi8g137yipTNKZkv6XJJnZ2ZIWSvq9pL6SBktaJekNMxsSP6dI0iuSRku6RFJnSVMl7ZE0KdxvA0CYjCvnAgibmX0iaZa7vxx/fI+k0e7+NTN7XdJqd/9eyte8IGm3u99oZrMk/b2koe5eHXL5ACLEjAuASJlZf0mXStpoZu0Vmzn5bT2n/qekGfHPL5L0IqEFyD8EFwBRecbM9kvaKmmXpL+R1E2xv5d21HP+DkmJ/pXuDZwDIMcRXABE5Qp37ySpXNJIxULJF5KOSepTz/l9JH0e/3xPA+cAyHEEFwCRcvclkh6U9M/ufkDSUkl/Ws+pVyvWkCtJL0u62Mw6hFIkgIxBcAGQCe6VNMPMyiTdLenbZnanmXUys1PM7KeSzpb0t/Hz/0OxJabfmdlIM2tjZt3N7K/M7LJovgUAYSC4AIicu++W9LCkv3b3P0q6WNK3FOtj2aLYdulp7r4hfv4RxRp0P5C0SNKXkpYrttz0VujfAIDQsB0aAABkDWZcAABA1iC4AACArEFwAQAAWYPgAgAAskbbqAtorh49evigQYMCee0DBw6oQwcuCxEmxjxcjHe4GO9wMd7hC3LM33777c/dvWfq8awLLoMGDdLKlSsDee2KigqVl5cH8tqoH2MeLsY7XIx3uBjv8AU55ma2pb7jLBUBAICsQXABAABZg+ACAACyBsEFAABkDYILAADIGgQXAACQNQguAAAgaxBcAABA1iC4AACArEFwAQAAWYPgAgAAsgbBBQAAZA2CCwAAyBoEFwAAkDUILgAAIGsQXAAAQNYguAAAgKxBcAEAAFkjsOBiZg+Y2S4zW9PA82ZmvzCzjWb2vpmND6oWAACQG4KccXlQ0iWNPH+ppOHxj9mSfh1gLQAAIAe0DeqF3f01MxvUyCmXS3rY3V3SMjPramZ93H1HUDW12Pz50mOPRV1FTimrqpK6do26jLzBeIeL8Q4X4x0ej/93WI8eUnl5qO8dWHBJQz9JW5MeV8aPfSW4mNlsxWZl1Lt3b1VUVARSUHV19Vdeu89zz6n3K69IkrquWiVJqiotDeT981FdXZ2qqqqiLiNvMN7hYrzDxXiH55i7jh49qqOdOwf2O7khUQYXq+eY13NM7j5f0nxJmjBhgpcHlO4qKip0wmvPny/9y7/EPj///NjHddep6+zZgbx/PvrKmCNQjHe4GO9wMd7Biy2SSGam6upqrV+xQtPzaMalUtKApMf9JW2PqJb6JZaF5s2TCCsAgDzm7nrppZckSRdffLE6duwos/rmIIIV5XboZyXdGN9dNEXSvozpb5k/P7Zm9957sVkWQgsAII8lQstbb70VdSnBzbiY2eOSyiX1MLNKSX8jqVCS3H2upOclXSZpo6SDkm4OqpZmmT9fuu222OfxpSEAAPJVcmiZPHmyLr744khmWhKC3FV0bRPPu6S/COr9TxrLQwAAHLdo0aKMCS1StD0uGafPc89JS5awPAQAQNzAgQMlSTNmzIg8tEgElxMktj2zPAQAyGfurs8++0x9+vTRyJEjNXLkyKhLOo57FaVitgUAkMcSPS333XefduzIjD0zyQguAABA0omNuJMmTdKpp54adUlfQXABAAAZt3uoIQQXAACgDRs2ZHxokWjOBQAAkoYPH65rr71Ww4cPz9jQIjHjAgBA3nJ3VVRUaNeuXTIzjRgxIqNDi8SMCwAAeSn1Mv69evWKuKL0MOMCAECeSW3EPf/886MuKW0EFwAA8ki27B5qCMEFAIA8UldXp507d2ZlaJHocQEAIC+4u2pra1VYWKjrr79eBQUFWRdaJGZcAADIeYnloYcfflg1NTVq27ZtVoYWieACAEBOS+5p6devn9q2ze7FFoILAAA5KtsbcetDcAEAIEe99tprORVaJJpzAQDIWWPHjpUknXfeeTkRWiRmXAAAyCnurnXr1snd1a1bN51//vk5E1okggsAADkj0dPy29/+VuvXr4+6nEAQXAAAyAGpjbijRo2KuqRAEFwAAMhyubh7qCEEFwAAstzu3bu1cuXKnA8tEruKAADIer169dLs2bPVs2fPnA4tEjMuAABkpcTy0Pvvvy8pFl5yPbRIBBcAALJOIrQsW7ZMO3bsiLqcUBFcAADIIqmNuDNnzoy6pFARXAAAyBL5tHuoIQSXhPnz1XXVqqirAACgUcXFxXkbWiR2Ff2Xxx6L/fe666KtAwCAFO6u/fv3q3PnziovL5ekvAwtEjMuJ6gqLZVmz466DAAAjkssD82dO1dffvmlzCxvQ4tEcAEAIGMl97SMGzdOnTp1irqkyBFcAADIQDTi1o/gAgBABnrnnXcILfWgORcAgAxUWloqSRo/fjyhJQkzLgAAZAh319KlS3Xo0CG1bdtWZ511FqElBTMuAABkgOSeFkk6++yzI64oMzHjAgBAxFIbcadMmRJ1SRmL4AIAQITYPdQ8BBcAACJ06NAhffjhh4SWNNHjAgBABNxdktS+fXvdeuutateuHaElDcy4AAAQssTy0HPPPSd3V/v27QktaSK4AAAQouSelqKioqjLyToEFwAAQkIjbssRXAAACMnLL79MaGkhmnMBAAjJkCFDJEkXXXQRoeUkEVwAAAiQu2vbtm3q37+/hg4dqqFDh0ZdUlZjqQgAgIAkelp+85vfqLKyMupycgLBBQCAAKQ24vbr1y/qknICwQUAgFbG7qHgEFwAAGhlH3/8MaElIDTnAgDQyoYOHao///M/15AhQwgtrYwZFwAAWoG769VXX9X27dslxcILoaX1MeMCAEALJfe0SFLfvn0jrih3MeMCAEALpDbiTp8+PeqSchrBBQCAk8TuofARXAAAOEnHjh3TF198QWgJET0uAAA0k7vr6NGjKi4u1tVXX602bdoQWkLCjAsAAM2QWB7693//dx05ckQFBQWElhARXAAASFNyT8ugQYNUVFQUdUl5h+ACAEAaaMTNDAQXAADS8Mc//pHQkgFozgUAIA2lpaWSpGnTphFaIsSMCwAADXB3rV69WseOHVPnzp117rnnEloixowLAAD1SL2M/9ixYyOuCBIzLgAAfEVqI+6YMWOiLglxBBcAAJKweyizEVwAAEiyd+9evf3224SWDEWPCwAASbp37645c+aoW7duhJYMxIwLACDvubtefPFFrVy5UlIsvBBaMhPBBQCQ15J7Wvbs2RN1OWgCwQUAkLdSG3FnzpwZdUloAsEFAJCX2D2UnQguAIC8ZGbq3LkzoSXLsKsIAJBX3F1VVVU65ZRTNHXqVLk7oSWLMOMCAMgbieWhefPm6YsvvpAkQkuWIbgAAPJCck9LWVmZunbtGnVJOAkEFwBAzqMRN3cQXAAAOW/VqlWElhxBcy4AIOeNHTtWklRaWkpoyXLMuAAAcpK764033tCBAwdUUFCgsrIyQksOYMYFAJBzkntaJOmcc86JuCK0FmZcAAA5JbURd+rUqVGXhFZEcAEA5Ax2D+W+QIOLmV1iZh+a2UYzu7ue57uY2XNmtsrM1prZzUHWAwDIbUeOHNGmTZsILTkssB4XMyuQ9CtJMyRVSlphZs+6+7qk0/5C0jp3/4aZ9ZT0oZk96u5Hg6oLAJB73F3urpKSEt1yyy0qLi4mtOSoIGdcJkna6O4fx4PIAkmXp5zjkjpZ7Kero6S9kmoDrAkAkGMSy0Pr16/XsWPHVFJSQmjJYUHuKuonaWvS40pJk1PO+aWkZyVtl9RJ0p+5+7HUFzKz2ZJmS1Lv3r1VUVHR6sWWVVWprq4ukNdGw6qrqxnzEDHe4WK8g+fu2rRpk7Zt26ZevXppyZIlhJYQRfEzHmRwqe8nx1MeXyzpPUkXSBoqaZGZve7uX57wRe7zJc2XpAkTJnh5eXnrV9u1q6qqqhTIa6NBFRUVjHmIGO9wMd7BSsy0bNu2TZMnT1ZxcbGmT58edVl5JYqf8SCXiiolDUh63F+xmZVkN0t6ymM2StosaWSANQEAcsQrr7zC7qE8FOSMywpJw81ssKRtkq6RdF3KOZ9KulDS62bWW9Lpkj4OsCYAQI4YMWKEJOnCCy8ktOSRwIKLu9ea2e2SXpJUIOkBd19rZnPiz8+V9BNJD5rZasWWlu5y98+DqgkAkN3cXVu2bNGgQYM0cOBADRw4MOqSELJAL/nv7s9Lej7l2Nykz7dLmhlkDQCA3JB8cblvf/vbGjRoUNQlIQJcORcAkPFSr4h72mmnRV0SIkJwAQBkNC7jj2QEFwBARvv0008JLTgu0B4XAABa6rTTTtNNN92kgQMHElrAjAsAIPO4u15++WV9+umnkmLhhdACiRkXAECGSe5pMTO2POMEzLgAADJGaiPuBRdcEHVJyDAEFwBARmD3ENJBcAEAZAR314EDBwgtaBQ9LgCASLm7jhw5opKSEl155ZUyM0ILGsSMCwAgMonlofvvv1+HDx9WmzZtCC1oFMEFABCJ5J6WYcOGqbi4OOqSkAUILgCA0NGIi5NFcAEAhO7NN98ktOCk0JwLAAhdWVmZJGnq1KmEFjQLMy4AgFC4u959913V1dWpQ4cOOueccwgtaDZmXAAAgUu9jH9ixgVoLmZcAACBSm3ELS0tjbokZDGCCwAgMOweQmsjuAAAArNv3z699957hBa0GnpcAACtzt1lZuratavmzJmjLl26EFrQKphxAQC0qsTy0BtvvCFJ6tq1K6EFrYbgAgBoNck9Lfv375e7R10ScgzBBQDQKmjERRgILgCAVrFw4UJCCwJHcy4AoFV0795dU6ZM0cyZMwktCAzBBQBw0txde/fuVffu3TVhwoSoy0EeYKkIAHBSEj0tc+fO1Z49e6IuB3mC4AIAaLbkRtyzzjpL3bp1i7ok5AmCCwCgWdg9hCgRXAAAzbJmzRpCCyJDcy4AoFlGjx4tSRozZgyhBaFjxgUA0CR31+uvv659+/apTZs2Gjt2LKEFkSC4AAAalehpefXVV/X+++9HXQ7yHMEFANCg1EbcadOmRV0S8hzBBQBQL3YPIRMRXAAA9aqpqdGWLVsILcgo7CoCAJzA3XXs2DEVFRXp5ptvVmFhIaEFGYMZFwDAcYnloSeeeEJ1dXUqKioitCCjEFwAAJJO7Gnp1q2b2rThVwQyDz+VAAAacZE1CC4AAC1evJjQgqxAcy4AQKNGjZIkTZ8+ndCCjEZwAYA85e76+OOPNXToUPXp00d9+vSJuiSgSSwVAUAeSvS0PPLII9q0aVPU5QBpI7gAQJ5JbcQdMmRI1CUBaSO4AEAeYfcQsh3BBQDyyLZt2wgtyGo05wJAHunfv79mzZqlvn37ElqQlZhxAYAc5+5atGiRNm7cKEnq168foQVZi+ACADks0dPy5ptvavPmzVGXA7QYwQUAclRqI+5FF10UdUlAixFcACAHsXsIuYrgAgA56ujRo4QW5Bx2FQFADnF3HTp0SO3bt9c3vvENSSK0IKcw4wIAOSKxPDR//nwdPHhQZkZoQc4huABADkjuaRk5cqTatWsXdUlAIAguAJDlaMRFPiG4AECWe+uttwgtyBs05wJAlisrK5MkTZ48mdCCnMeMCwBkIXfX22+/rZqaGpWUlGjKlCmEFuQFZlwAIMsk97RI0llnnRVxRUB4mHEBgCyS2og7fvz4qEsCQkVwAYAswe4hgOACAFlj//79Wr16NaEFeY0eFwDIcO4uSercubNuu+02derUidCCvMWMCwBksMTy0OLFi+Xu6ty5M6EFeY3gAgAZKrmn5ejRo1GXA2QEggsAZCAacYH6EVwAIAMtXLiQ0ALUg+ZcAMhAffv21ZQpUzRz5kxCC5CE4AIAGcLdtXv3bvXq1Utjx47V2LFjoy4JyDgsFQFABkj0tMybN0+7du2KuhwgYxFcACBiyY24EydOVM+ePaMuCchYBBcAiBC7h4DmIbgAQIQ++OADQgvQDDTnAkCERo4cqauvvlojR44ktABpYMYFAELm7lqyZIn27t0rM9OoUaMILUCaCC4AEKJET0tFRYVWr14ddTlA1iG4AEBIUhtxzzvvvKhLArIOwQUAQsDuIaB1EFwAIAS1tbXatm0boQVoIXYVAUCA3F11dXUqLCzUjTfeqLZt2xJagBYIdMbFzC4xsw/NbKOZ3d3AOeVm9p6ZrTWzJUHWAwBhSiwPPfroo6qtrVVhYSGhBWihwGZczKxA0q8kzZBUKWmFmT3r7uuSzukq6d8kXeLun5pZr6DqAYAwubs2bdp0fHmooKAg6pKAnBDkjMskSRvd/WN3PyppgaTLU865TtJT7v6pJLk7dxYDkPUSMy30tACtL8gel36StiY9rpQ0OeWcEZIKzaxCUidJ/+ruD6e+kJnNljRbknr37q2KiopWL7asqkp1dXWBvDYaVl1dzZiHiPEOxyeffKItW7aoV69eKi4u1pIlrIKHgZ/v8EUx5kEGl/r+eeH1vP9Zki6U1E7SUjNb5u4fnfBF7vMlzZekCRMmeHl5eetX27WrqqqqFMhro0EVFRWMeYgY73Ds3r1ba9eulbtr+vTpUZeTN/j5Dl8UY57WUpGZFZnZsGa+dqWkAUmP+0vaXs85L7r7AXf/XNJrkkqb+T4AEDl314cffih3V8+ePVVeXs7yEBCAJoOLmX1N0mpJi+KPy8zs6TRee4Wk4WY22MyKJF0j6dmUc34v6Vwza2tm7RVbSlrfnG8AAKKW6GlZsGCBPvroo6a/AMBJS2ep6O8UCxSLJcnd30tn9sXda83sdkkvSSqQ9IC7rzWzOfHn57r7ejN7UdL7ko5Jut/d15zk9wIAoUu9Iu6IESOiLgnIaekElxp3r0qZ8kztVamXuz8v6fmUY3NTHv+TpH9K5/UAIJNwGX8gfOkEl/VmdrWkNmY2WNJ/k7Qs2LIAIPPt3LlTy5cvJ7QAIUqnOfd2xXb+HJP0lKTDioUXAMhrp556qmbPnk1oAUKUTnC52N3vcvcz4x93S7o06MIAIBO5uxYuXKj162P7CE499VRCCxCidILLj+o59sPWLgQAMl2ip2Xp0qXaunVr018AoNU12ONiZhdLukRSPzP7l6SnOiu2bAQAeSO1EXfGjBlRlwTkpcaac3dJWqNYT8vapOP7JdV7p2cAyEXsHgIyR4PBxd3flfSumT3q7odDrAkAMo6ZEVqADJDOduh+Zvb3ks6QVJI46O5cZQlATnN3HThwQB07dtTMmTMlidACRCyd5twHJf27YjdNvFTSf0paEGBNABC5xPLQvHnzVF1dLTMjtAAZIJ3g0t7dX5Ikd9/k7j+SxO1OAeSs5J6W0aNHq0OHDlGXBCAunaWiIxb7Z8am+H2GtknqFWxZABANGnGBzJZOcPlLSR0l3Snp7yV1kfSdIIsCgKisWLGC0AJksCaDi7u/Ff90v6QbJMnM+gdZFABEpaysTJI0ceJEQguQgRrtcTGziWZ2hZn1iD8ebWYPi5ssAsgh7q7ly5fryJEjKioq0qRJkwgtQIZqMLiY2T9KelTS9ZJeNLMfSlosaZUktkIDyAmJnpYXXnhBq1atirocAE1obKnockml7n7IzLpJ2h5//GE4pQFAsFIbcSdOnBh1SQCa0NhS0WF3PyRJ7r5X0geEFgC5gt1DQHZqbMZliJk9Ff/cJA1Keix3/1aglQFAgA4cOKB169YRWoAs01hw+ZOUx78MshAACIO7S5I6duyo2bNnq0OHDoQWIIs0dpPFV8IsBACCllgecnddcskl6tixY9QlAWimdC75DwBZL7mnhRkWIHsRXADkPBpxgdyRdnAxs+IgCwGAoCxatIjQAuSIJi/5b2aTJP1GsXsUDTSzUkmz3P2OoIsDgNYwcOBASdKMGTMILUCWS2fG5ReSvi5pjyS5+ypJ04MsCgBayt21Y8cOSdLIkSM1c+ZMQguQA9IJLm3cfUvKsbogigGA1pDoabnvvvuOhxcAuaHJpSJJW+PLRW5mBZLukPRRsGUBwMlJbcQ99dRToy4JQCtKZ8blu5J+IGmgpJ2SpsSPAUBGYfcQkPvSmXGpdfdrAq8EAFpow4YNhBYgx6UTXFaY2YeSnpD0lLvvD7gmADgpw4cP17XXXqvhw4cTWoAc1eRSkbsPlfRTSWdJWm1mz5gZMzAAMoK7a/Hixdq1a5fMTCNGjCC0ADksrQvQufub7n6npPGSvpT0aKBVAUAaEj0tr732mtauXRt1OQBC0GRwMbOOZna9mT0nabmk3ZKmBl4ZADQitRG3vLw86pIAhCCdHpc1kp6TdI+7vx5wPQDQJHYPAfkrneAyxN2PBV4JAKSprq5Ou3fvJrQAeajB4GJm/5+7/3dJvzMzT33e3b8VaGUAkMLdVVtbq8LCQl177bUqKCggtAB5prEZlyfi//1lGIUAQGMSy0OVlZX69re/rcLCwqhLAhCBBptz3X15/NNR7v5K8oekUeGUBwAn9rT0799fbdums8oNIBelsx36O/Ucu6W1CwGA+tCICyBZYz0ufybpGkmDzeyppKc6SaoKujAAkKTXXnuN0ALguMbmW5dL2iOpv6RfJR3fL+ndIIsCgIRx48bJzHTuuecSWgA0HFzcfbOkzZJeDq8cAIgtD61fv16jRo3SKaecovPOOy/qkgBkiAZ7XMxsSfy/X5jZ3qSPL8xsb3glAsgniZ6W3/72t1q/fn3U5QDIMI0tFU2P/7dHGIUAQGoj7qhRbGAEcKLGtkMnrpY7QFKBu9dJOlvSbZI6hFAbgDzC7iEA6UhnO/QzktzMhkp6WLFruDwWaFUA8s7nn3+ulStXEloANCqdqzgdc/caM/uWpHvd/Rdmxq4iAK2qZ8+euu2229SjRw9CC4AGpTPjUmtmfyrpBkl/iB/jWtsAWiyxPLRq1SpJsfBCaAHQmHSvnDtd0j3u/rGZDZb0eLBlAch1idCybNkyffbZZ1GXAyBLNLlU5O5rzOxOScPMbKSkje7+98GXBiBXpTbizpw5M+qSAGSJJoOLmZ0r6T8kbZNkkk41sxvc/Y2giwOQe9g9BKAl0mnO/bmky9x9nSSZ2SjFgsyEIAsDkJvMTCUlJYQWACclneBSlAgtkuTu682sKMCaAOQgd9eXX36pLl26qLy8XO5OaAHQbOk0575jZvPMbFr849fiJosAmiGxPDRv3jzt27dPkggtAE5KOsFljqRNkv6npLskfazY1XMBoEnJPS3jxo1T586doy4JQBZrdKnIzMZKGirpaXe/J5ySAOQKGnEBtLbG7g79V4pd7v96SYvM7DuhVQUgJ7zzzjuEFgCtqrEZl+sljXP3A2bWU9Lzkh4IpywAuaC0tFRmpjPPPJPQAqBVNNbjcsTdD0iSu+9u4lwAkBRbHlq6dKkOHTqktm3bavz48YQWAK2msRmXIWb2VPxzkzQ06bHc/VuBVgYg6yT3tEjS2WefHXFFAHJNY8HlT1Ie/zLIQgBkt9RG3ClTpkRdEoAc1GBwcfdXwiwEQPZi9xCAsNC3AqDFDh06pA8//JDQAiBw6VzyHwDq5e6SpPbt2+vWW29Vu3btCC0AApX2jIuZFQdZCIDsklgeevbZZ+Xuat++PaEFQOCaDC5mNsnMVkvaEH9camb/N/DKAGSs5J6W4mL+TQMgPOnMuPxC0tcl7ZEkd18laXqQRQHIXDTiAohSOsGljbtvSTlWF0QxADLfyy+/TGgBEJl0mnO3mtkkSW5mBZLukPRRsGUByFRDhw6VJF100UWEFgChSye4fFex5aKBknZKejl+DECecHdVVlZqwIABGjJkiIYMGRJ1SQDyVJNLRe6+y92vcfce8Y9r3P3zMIoDEL1ET8sDDzygrVu3Rl0OgDzX5IyLmd0nyVOPu/vsQCoCkDFSG3H79+8fdUkA8lw6S0UvJ31eIulKSfyzC8hx7B4CkImaDC7u/kTyYzP7D0mLAqsIQEbYvHkzoQVAxjmZS/4PlnRaaxcCILMMGTJEN9xwgwYPHkxoAZAx0rly7hdmtjf+UaXYbMtfBV8agLC5u1555RVt375dUiy8EFoAZJJGZ1ws9jdWqaRt8UPHPHFXNQA5JbmnxczUt2/fqEsCgK9odMYlHlKedve6+AehBchBqY2406dzVw8AmSmdS/4vN7PxgVcCIBLsHgKQTRpcKjKztu5eK2mapFvNbJOkA5JMsckYwgyQA44dO6aqqipCC4Cs0FiPy3JJ4yVdEVItAELk7jp69KiKi4v1p3/6p2rTpg2hBUDGayy4mCS5+6aQagEQksTy0ObNm/Wd73xHxcXFUZcEAGlpLLj0NLMfNPSku/9LAPUACFhqT0tRUVHUJQFA2hprzi2Q1FFSpwY+mmRml5jZh2a20czubuS8iWZWZ2ZXpV86gOaiERdAtmtsxmWHu//dyb6wmRVI+pWkGZIqJa0ws2fdfV095/0fSS+d7HsBSM/WrVu1efNmQguArNVkj0sLTJK00d0/liQzWyDpcknrUs67Q9LvJE1s4fsBaELv3r01ZMgQnXPOOYQWAFmpseByYQtfu59OvIt0paTJySeYWT/F7jZ9gRoJLmY2W9JsKfYXb0VFRQtL+6qyqirV1dUF8tpoWHV1NWMeMHfXrl271KtXL9XU1Ki2tlZLliyJuqy8wM93uBjv8EUx5g0GF3ff28LXru+fc6lX3r1X0l3uXtfYv/7cfb6k+ZI0Ya/NM1kAAB+qSURBVMIELy8vb2Fp9ejaVVVVVQrktdGgiooKxjxAiZ6WDz74QKNGjZKZMd4h4uc7XIx3+KIY83SunHuyKiUNSHrcX9L2lHMmSFpgZp9IukrSv5kZ140BWkFqI+7YsWOjLgkAWqzRmyy20ApJw81ssGI3abxG0nXJJ7j74MTnZvagpD+4+zMB1gTkBXYPAchVgQUXd681s9sV2y1UIOkBd19rZnPiz88N6r2BfLd371698847hBYAOSfIGRe5+/OSnk85Vm9gcfebgqwFyCfdu3fXbbfdpm7duhFaAOSUIHtcAIQosTy0fPlySbHwQmgBkGsILkAOSISWZcuW6Ysvvoi6HAAIDMEFyHKpjbgzZ86MuiQACAzBBchy7B4CkE8ILkCW69KlC6EFQN4IdFcRgGC4u6qqqnTKKafo7LPPjrocAAgNMy5Alkn0tMydO5dGXAB5h+ACZJHkRtwzzzxTXbt2jbokAAgVwQXIElzGHwAILkDWWLVqFaEFQN6jORfIEmPHjpWZady4cYQWAHmLGRcgg7m73njjDVVXV6ugoEClpaWEFgB5jRkXIEMl97RI0jnnnBNxRQAQPWZcgAyU2og7derUqEsCgIxAcAEyDLuHAKBhBBcgwxw5ckSbNm0itABAPehxATKEu8vdVVJSoltuuUXFxcWEFgBIwYwLkAESy0O/+93vdOzYMZWUlBBaAKAeBBcgYsk9LZ06dSKwAEAjCC5AhGjEBYDmIbgAEXr11VcJLQDQDDTnAhEaMWKEJOmCCy4gtABAGgguQMjcXVu2bNGgQYM0YMAADRgwIOqSACBrsFQEhCjR0/LQQw/pk08+ibocAMg6BBcgJKmNuKeddlrUJQFA1iG4ACFg9xAAtA6CCxCCrVu3EloAoBXQnAuEYODAgbr55ps1YMAAQgsAtAAzLkBA3F0vv/yytmzZIikWXggtANAyzLgAAUjuaZFEIy4AtBJmXIBWltqIe+GFF0ZdEgDkDIIL0IrYPQQAwSK4AK3I3XXw4EFCCwAEhB4XoBW4uw4fPqx27drpiiuukJkRWgAgAMy4AC2UWB66//77dejQIbVp04bQAgABIbgALZDc0zJ8+HCVlJREXRIA5DSCC3CSaMQFgPARXICTtHTpUkILAISM5lzgJJWWlkqSzj77bEILAISEGRegGdxd7777rurq6tShQwdNnTqV0AIAIWLGBUhT6mX8zzzzzIgrAoD8w4wLkIbURtyysrKoSwKAvERwAZrA7iEAyBwEF6AJ+/bt03vvvUdoAYAMQI8L0AB3l5mpa9eumjNnjrp06UJoAYCIMeMC1COxPPTHP/5RktS1a1dCCwBkAIILkCK5p6W6ulruHnVJAIA4gguQhEZcAMhsBBcgycKFCwktAJDBaM4FkvTs2VNTpkzRzJkzCS0AkIEILsh77q49e/aoR48eGj9+fNTlAAAawVIR8lqip2XevHn6/PPPoy4HANAEggvyVnIj7llnnaXu3btHXRIAoAkEF+Qldg8BQHYiuCAvrV27ltACAFmI5lzkpdGjRx//L6EFALIHMy7IG+6u119/Xfv27ZOZacyYMYQWAMgyBBfkhURPy6uvvqr3338/6nIAACeJ4IKcl9qIO23atKhLAgCcJIILchq7hwAgtxBckNNqamq0ZcsWQgsA5Ah2FSEnubuOHTumoqIi3XzzzSosLCS0AEAOYMYFOSexPPTEE0+orq5ORUVFhBYAyBEEF+SU5J6Wbt26qU0bfsQBIJfwtzpyBo24AJD7CC7IGYsXLya0AECOozkXOWPUqFGSpOnTpxNaACBHEVyQ1dxdmzZt0rBhw9SnTx/16dMn6pIAAAFiqQhZK9HT8uijj2rjxo1RlwMACAHBBVkptRF36NChUZcEAAgBwQVZh91DAJC/CC7IOtu3bye0AECeojkXWadfv36aNWuW+vbtS2gBgDzDjAuygrtr0aJFx5tw+/XrR2gBgDxEcEHGS/S0vPnmm9q8eXPU5QAAIkRwQUZLbcS96KKLoi4JABAhggsyFruHAACpCC7IaLW1tYQWAMBx7CpCxnF3HTx4UB06dNDXvvY1SSK0AAAkMeOCDJNYHrrvvvt04MABmRmhBQBwHMEFGSO5p2XkyJFq37591CUBADIMwQUZgUZcAEA6CC7ICG+99RahBQDQpECbc83sEkn/KqlA0v3u/rOU56+XdFf8YbWk77r7qiBrQmYqKyuTJE2ePJnQAgBoUGAzLmZWIOlXki6VdIaka83sjJTTNks6393HSfqJpPlB1YPM4+7avn27ampqVFJSoilTphBaAACNCnKpaJKkje7+sbsflbRA0uXJJ7j7m+7+RfzhMkn9A6wHGSTR07JhwwatWsUkGwAgPUEuFfWTtDXpcaWkyY2cf4ukF+p7wsxmS5otSb1791ZFRUUrlfhfyqqqVFdXF8hr40Turk2bNmnbtm3q1auX9u/fz7iHpLq6mrEOEeMdLsY7fFGMeZDBpb45f6/3RLPpigWXafU97+7zFV9GmjBhgpeXl7dSiUm6dlVVVZUCeW0cl5hp2bZtmyZPnqzi4mJNnz496rLyRkVFBT/jIWK8w8V4hy+KMQ9yqahS0oCkx/0lbU89yczGSbpf0uXuvifAepAB9u/fr9WrV7N7CABwUoKccVkhabiZDZa0TdI1kq5LPsHMBkp6StIN7v5RgLUgYu6xybbOnTvrtttuU6dOnQgtAIBmCyy4uHutmd0u6SXFtkM/4O5rzWxO/Pm5kv63pO6S/i3+S6zW3ScEVROikVgeKiws1AUXXKDOnTtHXRIAIEsFeh0Xd39e0vMpx+YmfT5L0qwga0C0Uq+ICwBAS3DlXASGy/gDAFobwQWBWbhwIaEFANCqAl0qQn7r16+fpkyZopkzZxJaAACtguCCVuXu2rVrl3r37q0xY8ZozJgxUZcEAMghLBWh1SR6WubPn6+dO3dGXQ4AIAcRXNAqkhtxJ06cqF69ekVdEgAgBxFc0GLsHgIAhIXgghb74IMPCC0AgFDQnIsWGzlypK6++mqNHDmS0AIACBQzLjgp7q4lS5Zoz549MjONGjWK0AIACBzBBc2W6GmpqKjQmjVroi4HAJBHCC5oltRG3PPOOy/qkgAAeYTggrSxewgAEDWCC9JWW1ur7du3E1oAAJFhVxGa5O6qq6tTYWGhbrjhBrVt25bQAgCIBDMuaFRieeiRRx5RbW2tCgsLCS0AgMgQXNCg5J6WU089VQUFBVGXBADIcwQX1ItGXABAJiK4oF5LliwhtAAAMg7NuajXmDFjJEnnn38+oQUAkDGYccFx7q4PP/xQ7q4ePXqovLyc0AIAyCgEF0j6r56WBQsW6KOPPoq6HAAA6kVwwVcacUeMGBF1SQAA1IvgkufYPQQAyCYElzy3c+dOrVixgtACAMgK7CrKc6eeeqpuvfVW9e7dm9ACAMh4zLjkIXfXwoULtW7dOkmx8EJoAQBkA4JLnkn0tCxdulSVlZVRlwMAQLMQXPJIaiPujBkzoi4JAIBmIbjkCXYPAQByAcElj7Rp04bQAgDIauwqynHururqanXq1On40hChBQCQrZhxyWGJ5aF58+Zp//79MjNCCwAgqxFcclRyT8uYMWPUsWPHqEsCAKDFCC45iEZcAECuIrjkoJUrVxJaAAA5iebcHFRaWipJmjBhAqEFAJBTmHHJEe6ut956S0eOHFFRUZEmTpxIaAEA5BxmXHJAck+LJE2ePDniigAACAYzLlkutRF30qRJUZcEAEBgCC5ZjN1DAIB8Q3DJYgcPHtS6desILQCAvEGPSxZyd0lShw4ddNttt6l9+/aEFgBAXmDGJcsklodeeOEFubs6dOhAaAEA5A2CSxZJ7mlp04Y/OgBA/uG3X5agERcAAIJL1li0aBGhBQCQ92jOzRKnnXaaJGnGjBmEFgBA3iK4ZDB3144dO9S3b1+dfvrpOv3006MuCQCASLFUlKESPS3333+/tm/fHnU5AABkBIJLBkpuxJ00aZL69OkTdUkAAGQEgkuGYfcQAAANI7hkmI0bNxJaAABoAM25GWbYsGG67rrrNGzYMEILAAApmHHJAO6uxYsXa+fOnTIzDR8+nNACAEA9mHGJWHJPiyT17t074ooAAMhczLhEKLURt7y8POqSAADIaASXiLB7CACA5iO4RKSurk67d+8mtAAA0Az0uITM3VVTU6OioiJde+21KigoILQAAJAmZlxClFgeeuihh3T06FG1bduW0AIAQDMQXEKS3NMyYMAAFRYWRl0SAABZh+ASAhpxAQBoHQSXELz++uuEFgAAWgHNuSEYN26cJOncc88ltAAA0ALMuATE3bV27Vq5u7p27arzzjuP0AIAQAsRXAKQ6Gl58skntW7duqjLAQAgZxBcWllqI+4ZZ5wRdUkAAOQMgksrYvcQAADBIri0os8//1wrV64ktAAAEBB2FbWinj176rbbblOPHj0ILQAABIAZlxZKLA+99957kmLhhdACAEAwmHFpgeSelilTpkRdDgAgDTU1NaqsrNThw4ejLiXrdenSRevXr2/Ra5SUlKh///5p3wqH4HKSUhtxZ86cGXVJAIA0VFZWqlOnTho0aBAz5C20f/9+derU6aS/3t21Z88eVVZWavDgwWl9DUtFJ4HdQwCQvQ4fPqzu3bvz93YGMDN17969WbNfBJeTYGZq164doQUAshR/b2eO5v5ZsFTUDO6uL7/8Ul26dNH5558vd+eHHwCAEDHjkqbE8tDcuXO1b98+SSR2AMDJ++yzz3TNNddo6NChOuOMM3TZZZdp/vz5+vrXvx51aRmN4JKG5J6W0tJSde7cOeqSAABZzN115ZVXqry8XJs2bdK6dev0D//wD9q5c2fUpWU8loqaQCMuAOS2Bx988CvHRo8erYkTJ6qmpkaPPvroV54vKytTWVmZDh48qP/8z/884bmbbrqpyfdcvHixCgsLNWfOnBNes6qqSq+88oquuuoqrVmzRmeddZYeeeQRmZn+7u/+Ts8995wOHTqkqVOnat68eTIzlZeXa/LkyVq8eLGqqqr0m9/8Rueee67q6up011136aWXXpKZ6dZbb9Udd9yht99+Wz/4wQ9UXV2tHj166MEHH1SfPn2aPW5RYcalCe+++y6hBQDQqhKhpD7vvvuu7r33Xq1bt04ff/yx3njjDUnS7bffrhUrVmjNmjU6dOiQ/vCHPxz/mtraWi1fvlz33nuv/vZv/1aSNH/+fG3evFnvvvuu3n//fV1//fWqqanRHXfcoSeffFJvv/22vvOd7+iHP/xh8N9wK2LGpQnjxo2TJJ155pmEFgDIQY3NkBQWFjb6fPv27dOaYWmOSZMmqX///pJiszCffPKJpk2bpsWLF+uee+7RwYMHtXfvXo0ePVrf+MY3JEnf+ta3JElnnXWWPvnkE0nSyy+/rDlz5qht29iv+m7dumnNmjVas2aNZsyYIUmqq6vLqtkWieBSL3fXsmXLVFZWpnbt2mn8+PFRlwQAyCGjR4/Wk08+We9zxcXFxz8vKChQbW2tDh8+rO9973tauXKlBgwYoB//+McnXPsk8TWJ8yXVu/PV3TV69GgtXbq0tb+l0LBUlCLR07Jw4cLj9x8CAKA1XXDBBTpy5Ijuu+++48dWrFihJUuW1Ht+IqT06NFD1dXVDYaeZDNnztTcuXOPB5m9e/fq9NNP1+7du48Hl5qaGq1du7al306oAg0uZnaJmX1oZhvN7O56njcz+0X8+ffNLNKpDZdOaMTl/kMAgCCYmZ5++mktWrRIQ4cO1ejRo/XjH/9Yffv2rff8rl276tZbb9XYsWN1xRVXaOLEiU2+x6xZszRw4ECNGzdOpaWleuyxx1RUVKQnn3xSd911l0pLS1VWVqY333yztb+9QJm7B/PCZgWSPpI0Q1KlpBWSrnX3dUnnXCbpDkmXSZos6V/dfXJjrzthwgRfuXJlq9fr5eX6bMcOzb/uOhpxQ1RRUaHy8vKoy8gbjHe4GO9wpTve69ev16hRo4IvKA+09F5FCfX9mZjZ2+4+IfXcIGdcJkna6O4fu/tRSQskXZ5yzuWSHvaYZZK6mlkkXULHjh1TTU0NoQUAgAwWZHNuP0lbkx5XKjar0tQ5/STtSD7JzGZLmi1JvXv3VkVFRWvXqmG9eqmmSxcVFxc3uMaI1lddXR3Inyfqx3iHi/EOV7rj3aVLF+3fvz/4gvJAXV1dq4zl4cOH0/5/JcjgUt+UReq6VDrnyN3nS5ovxZaKApl6LS9XRUWFpjOtGyqm0sPFeIeL8Q5Xc5aKWmN5A623VFRSUqIzzzwzrXODXCqqlDQg6XF/SdtP4hwAAABJwQaXFZKGm9lgMyuSdI2kZ1POeVbSjfHdRVMk7XP3HakvBAAAIAW4VOTutWZ2u6SXJBVIesDd15rZnPjzcyU9r9iOoo2SDkq6Oah6AABA9gv0Oi7u/ry7j3D3oe7+9/Fjc+OhRfHdRH8Rf36su7f+PmcAADLQ008/LTPTBx98cPxYRUWFvv71r59w3k033XT8gnM1NTW6++67NXz4cI0ZM0aTJk3SCy+80KI69uzZo+nTp6tjx466/fbbGzxv7969mjFjhoYPH64ZM2boiy++OP7cP/7jP2rYsGE6/fTT9dJLLx0//vbbb2vs2LEaNmyY7rzzTrXGJVi4ci4AABF4/PHHNW3aNC1YsCDtr/nrv/5r7dix4/g9h5577rkW7+opKSnRT37yE/3zP/9zo+f97Gc/04UXXqgNGzbowgsv1M9+9jNJ0rp167RgwQKtXbtWL774or73ve+prq5OkvTd735X8+fP14YNG7Rhwwa9+OKLLapV4l5FAIB89v3vS619e5eyMuneexs9pbq6Wm+88YYWL16sb37zm/rxj3/c5MsePHhQ9913nzZv3nz83kS9e/fW1Vdf3aJyO3TooGnTpmnjxo2Nnvf73//++Jblb3/72yovL9ePfvQj/f73v9c111yj4uJiDR48WMOGDdPy5cs1aNAgffnllzr77LMlSTfeeKOeeeYZXXrppS2ql+ACAEDInnnmGV1yySUaMWKEunXrpnfeeafJG/pu3LhRAwcOVOfOnZt8/b/8y7/U4sWLv3L8mmuu0d13f+UOPGnZuXPn8TtJ9+nTR7t27ZIkbdu27YRb5PTv31/btm1TYWHh8btcJx9vKYILACB/NTEzEpTHH39c3//+9yXFwsTjjz+u8ePHN3jV9uZezf3nP/95i2tMV319K2bW4PGWIrgAABCiPXv26NVXX9WaNWtkZqqrq5OZ6Z577lH37t1PaHqVYk2xPXr00LBhw/Tpp5+mddG3IGZcevfurR07dqhPnz7asWOHevXqJSk2k7J1639dBL+yslJ9+/ZV//79VVlZ+ZXjLUVzLgAAIXryySd14403asuWLfrkk0+0detWDR48WH/84x81fPhwbd++XevXr5ckbdmyRatWrVJZWZnat2+vW265RXfeeaeOHj0qSdqxY4ceeeSRr7zHz3/+c7333ntf+TjZ0CJJ3/zmN/XQQw9Jkh566CFdfvnlx48vWLBAR44c0ebNm7VhwwZNmjRJffr0UadOnbRs2TK5ux5++OHjX9MSBBcAAEL0+OOP68orrzzh2J/8yZ/oscceU3FxsR555BHdfPPNKisr01VXXaX7779fXbp0kST99Kc/Vc+ePXXGGWdozJgxuuKKK9SzZ88W1zRo0CD94Ac/0IMPPqj+/ftr3bp1kqRZs2Zp5crYlUruvvtuLVq0SMOHD9eiRYuOh6DRo0fr6quv1hlnnKFLLrlEv/rVr1RQUCBJ+vWvf61Zs2Zp2LBhGjp0aIsbcyXJWmNPdZgmTJjgiUFsbdxXJHyMebgY73Ax3uFqzr2KRo0aFXxBeaC17lVU35+Jmb3t7hNSz2XGBQAAZA2CCwAAyBoEFwBA3sm2Nolc1tw/C4ILACCvlJSUaM+ePYSXDODu2rNnj0pKStL+Gq7jAgDIK4nri+zevTvqUrLe4cOHmxU66lNSUnLCFXabQnABAOSVwsJCDR48OOoyckJFRYXOPPPMUN+TpSIAAJA1CC4AACBrEFwAAEDWyLor55rZbklbAnr5HpI+D+i1UT/GPFyMd7gY73Ax3uELcsxPc/ev3M8g64JLkMxsZX2XF0ZwGPNwMd7hYrzDxXiHL4oxZ6kIAABkDYILAADIGgSXE82PuoA8xJiHi/EOF+MdLsY7fKGPOT0uAAAgazDjAgAAsgbBBQAAZI28DC5mdomZfWhmG83s7nqeNzP7Rfz5981sfBR15oo0xvv6+Di/b2ZvmllpFHXmiqbGO+m8iWZWZ2ZXhVlfLkpnzM2s3MzeM7O1ZrYk7BpzSRp/p3Qxs+fMbFV8vG+Oos5cYWYPmNkuM1vTwPPh/s5097z6kFQgaZOkIZKKJK2SdEbKOZdJekGSSZoi6a2o687WjzTHe6qkU+KfX8p4BzveSee9Kul5SVdFXXc2f6T5M95V0jpJA+OPe0Vdd7Z+pDnefyXp/8Q/7ylpr6SiqGvP1g9J50kaL2lNA8+H+jszH2dcJkna6O4fu/tRSQskXZ5yzuWSHvaYZZK6mlmfsAvNEU2Ot7u/6e5fxB8uk5T+/c2RKp2fb0m6Q9LvJO0Ks7gclc6YXyfpKXf/VJLcnXE/eemMt0vqZGYmqaNiwaU23DJzh7u/ptgYNiTU35n5GFz6Sdqa9Lgyfqy55yA9zR3LWxRL7jg5TY63mfWTdKWkuSHWlcvS+RkfIekUM6sws7fN7MbQqss96Yz3LyWNkrRd0mpJ/83dj4VTXl4K9Xdm26BeOINZPcdS94Sncw7Sk/ZYmtl0xYLLtEArym3pjPe9ku5y97rYP0jRQumMeVtJZ0m6UFI7SUvNbJm7fxR0cTkonfG+WNJ7ki6QNFTSIjN73d2/DLq4PBXq78x8DC6VkgYkPe6vWCpv7jlIT1pjaWbjJN0v6VJ33xNSbbkonfGeIGlBPLT0kHSZmdW6+zPhlJhz0v075XN3PyDpgJm9JqlUEsGl+dIZ75sl/cxjDRgbzWyzpJGSlodTYt4J9XdmPi4VrZA03MwGm1mRpGskPZtyzrOSbox3Sk+RtM/dd4RdaI5ocrzNbKCkpyTdwL9AW6zJ8Xb3we4+yN0HSXpS0vcILS2Szt8pv5d0rpm1NbP2kiZLWh9ynbkinfH+VLHZLZlZb0mnS/o41CrzS6i/M/NuxsXda83sdkkvKdad/oC7rzWzOfHn5yq20+IySRslHVQsveMkpDne/1tSd0n/Fp8FqHXu8HpS0hxvtKJ0xtzd15vZi5Lel3RM0v3uXu/WUjQuzZ/xn0h60MxWK7aMcZe7fx5Z0VnOzB6XVC6ph5lVSvobSYVSNL8zueQ/AADIGvm4VAQAALIUwQUAAGQNggsAAMgaBBcAAJA1CC4AACBrEFyAPBK/G/R7SR+DGjl3UEN3g23me1bE7+S7yszeMLPTT+I15iQuk29mN5lZ36Tn7jezM1q5zhVmVpbG13w/fl0WACEhuAD55ZC7lyV9fBLS+17v7qWSHpL0T8394vi1UB6OP7xJUt+k52a5+7pWqfK/6vw3pVfn9yURXIAQEVyAPBefWXndzN6Jf0yt55zRZrY8PkvzvpkNjx//86Tj88ysoIm3e03SsPjXXmhm75rZajN7wMyK48d/Zmbr4u/zz/FjPzaz/2FmVyl2y4JH4+/ZLj5TMsHMvmtm9yTVfJOZ/d+TrHOpkm4SZ2a/NrOVZrbWzP42fuxOxQLUYjNbHD8208yWxsfxt2bWsYn3AdBMBBcgv7RLWiZ6On5sl6QZ7j5e0p9J+kU9XzdH0r+6e5liwaHSzEbFzz8nfrxO0vVNvP83JK02sxJJD0r6M3cfq9hVvL9rZt0Uu3P1aHcfJ+mnyV/s7k9KWqnYzEiZux9KevpJSd9Kevxnkp44yTovkZR8G4Qfxq/mPE7S+WY2zt1/odj9WKa7+3Qz6yHpR5Iuio/lSkk/aOJ9ADRT3l3yH8hzh+K/vJMVSvplvKejTtKIer5uqaQfmll/SU+5+wYzu1CxOx6viN+qoZ1iIag+j5rZIUmfSLpDsXvHbE66N9VDkv5C0i8lHZZ0v5n9/5L+kO435u67zezj+L1SNsTf44346zanzg6KXUp+fNLxq81stmJ/Z/aRdIZil+9PNiV+/I34+xQpNm4AWhHBBcBfStqp2N2K2ygWHE7g7o+Z2VuSvibpJTObpdg9YB5y9/+Vxntc7+4rEw/MrHt9J8XvQzNJsRvkXSPpdkkXNON7eULS1ZI+kPS0u7vFUkTadUpaJelnkn4l6VtmNljS/5A00d2/MLMHJZXU87UmaZG7X9uMegE0E0tFALpI2uHuxyTdoNhswwnMbIikj+PLI88qtmTyiqSrzKxX/JxuZnZamu/5gaRBZjYs/vgGSUviPSFd3P15xRpf69vZs19SpwZe9ylJV0i6VrEQo+bW6e41ii35TIkvM3WWdEDSPovdafjSBmpZJumcxPdkZu3NrL7ZK+D/tXf3qAkFURiG37MS2+zIMpuwdAtpRSyCpElhKwhaiJ3Y5AfjJlKkClh5LGZuI4Eg2gy8TzlcZoZbfcyZ4egGBhdJI+AxIraUMtHvH9/0gX1EvAMPwEt9yTMElhHxCawoZZR/ZeaR0kF2Vjv4noAxJQTM63wbymnQpSkw7i7nXsz7AxyAXmbu6tjV+6x3Z56AQWZ+AG/AF/BMKT91JsAiItaZ+U158fRa19lS/pWkO7I7tCRJaoYnLpIkqRkGF0mS1AyDiyRJaobBRZIkNcPgIkmSmmFwkSRJzTC4SJKkZpwBRjcg+MCWrb0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(y_binary, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34769693"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.mean(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9516363e-04],\n",
       "       [2.5775665e-02],\n",
       "       [9.7585344e-01],\n",
       "       ...,\n",
       "       [2.7344560e-05],\n",
       "       [1.9537615e-02],\n",
       "       [9.8265666e-01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33666666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006666666666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.sum(numpy.abs((r>0.5).reshape((1500,)) - y_binary)) / 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_submission = True # Switch this to True when you're ready to create a submission for Kaggle\n",
    "\n",
    "test_scores    = classifier.predict(test_data)\n",
    "test_scores = test_scores.reshape((test_scores.shape[0],))\n",
    "# Save the predictions to a CSV file for upload to Kaggle\n",
    "submission_file = pd.DataFrame({'id':    ids,\n",
    "                               'score':  test_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if produce_submission:\n",
    "    submission_file.to_csv('yyf_padding_cnn_4_layers.csv',\n",
    "                           columns=['id','score'],\n",
    "                           index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.068346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1501</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1502</td>\n",
       "      <td>0.998553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1503</td>\n",
       "      <td>0.881284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1504</td>\n",
       "      <td>0.002378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id     score\n",
       "0  1500  0.068346\n",
       "1  1501  0.000387\n",
       "2  1502  0.998553\n",
       "3  1503  0.881284\n",
       "4  1504  0.002378"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>1923</td>\n",
       "      <td>0.449591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     score\n",
       "423  1923  0.449591"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file[submission_file['id']==1923]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "npmat=submission_file.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.92300000e+03, 4.49590832e-01]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npmat[npmat[:,0]==1923,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
