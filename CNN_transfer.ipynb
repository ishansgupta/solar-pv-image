{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as metrics\n",
    "import PIL\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "img_width = 101\n",
    "img_height = 101\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "keras = tf.keras\n",
    "\n",
    "IMG_SHAPE = (img_height, img_width, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(labels, prediction_scores):\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, prediction_scores, pos_label=1)\n",
    "    auc = metrics.roc_auc_score(labels, prediction_scores)\n",
    "    legend_string = 'AUC = {:0.3f}'.format(auc)\n",
    "   \n",
    "    plt.plot([0,1],[0,1],'--', color='gray', label='Chance')\n",
    "    plt.plot(fpr, tpr, label=legend_string)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.grid('on')\n",
    "    plt.axis('square')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def load_data(dir_data, dir_labels, training=True):\n",
    "    ''' Load each of the image files into memory \n",
    "\n",
    "    While this is feasible with a smaller dataset, for larger datasets,\n",
    "    not all the images would be able to be loaded into memory\n",
    "\n",
    "    When training=True, the labels are also loaded\n",
    "    '''\n",
    "    labels_pd = pd.read_csv(dir_labels)\n",
    "    ids       = labels_pd.id.values\n",
    "    data      = []\n",
    "    for identifier in ids:\n",
    "        fname     = dir_data + identifier.astype(str) + '.tif'\n",
    "        image     = mpl.image.imread(fname)\n",
    "        data.append(image)\n",
    "    data = np.array(data) # Convert to Numpy array\n",
    "    if training:\n",
    "        labels = labels_pd.label.values\n",
    "        return data, labels\n",
    "    else:\n",
    "        return data, ids\n",
    "    \n",
    "def cv_performance_assessment(X,y,k,clf):\n",
    "    '''Cross validated performance assessment\n",
    "    \n",
    "    X   = training data\n",
    "    y   = training labels\n",
    "    k   = number of folds for cross validation\n",
    "    clf = classifier to use\n",
    "    \n",
    "    Divide the training data into k folds of training and validation data. \n",
    "    For each fold the classifier will be trained on the training data and\n",
    "    tested on the validation data. The classifier prediction scores are \n",
    "    aggregated and output\n",
    "    '''\n",
    "    # Establish the k folds\n",
    "    prediction_scores = np.empty(y.shape[0],dtype='object')\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "    for train_index, val_index in kf.split(X, y):\n",
    "        # Extract the training and validation data for this fold\n",
    "        X_train, X_val   = X[train_index], X[val_index]\n",
    "        y_train          = y[train_index]\n",
    "        \n",
    "        # Train the classifier\n",
    "        X_train_features = X_train\n",
    "        clf              = clf.fit(X_train_features,y_train)\n",
    "        \n",
    "        # Test the classifier on the validation data for this fold\n",
    "        X_val_features   = X_val\n",
    "        cpred            = clf.predict_proba(X_val_features)\n",
    "        \n",
    "        # Save the predictions for this fold\n",
    "        prediction_scores[val_index] = cpred[:,1]\n",
    "    return prediction_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image data\n",
    "train_data_dir = './data/training'\n",
    "test_data_dir = './data/testing'\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, vertical_flip = True, horizontal_flip=True,rotation_range=20,\n",
    "                                   shear_range=5.0, channel_shift_range=50.0,\n",
    "                                   validation_split = 0.15)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e1abfb049703>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midentifier\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mfname\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mdir_train_images\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0midentifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.tif'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mimage\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Convert to Numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1349\u001b[0m                              \u001b[1;34m'with Pillow installed matplotlib can handle '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m                              'more images' % list(handlers))\n\u001b[1;32m-> 1351\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1352\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2634\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2635\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run this\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "dir_train_images  = './data/training/'\n",
    "dir_test_images   = './data/testing/'\n",
    "dir_train_labels  = './data/labels_training.csv'\n",
    "dir_test_ids      = './data/sample_submission.csv'\n",
    "\n",
    "labels_pd = pd.read_csv(dir_train_labels)\n",
    "labels_0_sampled = labels_pd[labels_pd[\"label\"] == 0].sample(n = 505)\n",
    "labels_sampled = labels_0_sampled.append(labels_pd[labels_pd[\"label\"] == 1])\n",
    "ids       = labels_sampled.id.values\n",
    "data      = []\n",
    "for identifier in ids:\n",
    "    fname     = dir_train_images + identifier.astype(str) + '.tif'\n",
    "    image     = mpl.image.imread(fname)\n",
    "    data.append(image)\n",
    "data = np.array(data) # Convert to Numpy array\n",
    "\n",
    "\n",
    "X = data/1500\n",
    "y = labels_sampled.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1275 validated image filenames belonging to 2 classes.\n",
      "Found 225 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate image label dataframe\n",
    "# Dont run this\n",
    "traindf = pd.read_csv(\"./data/labels_training.csv\",dtype=str)\n",
    "def append_ext(fn):\n",
    "    return fn+\".tif\"\n",
    "traindf[\"id\"]=traindf[\"id\"].apply(append_ext)\n",
    "traindf = traindf.sample(frac=1)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe( \n",
    "    dataframe=traindf,\n",
    "    directory=train_data_dir, \n",
    "    x_col=\"id\",\n",
    "    y_col=\"label\",\n",
    "    seed=0,\n",
    "    batch_size = batch_size,\n",
    "    target_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe( \n",
    "    dataframe=traindf,\n",
    "    directory=train_data_dir, \n",
    "    x_col=\"id\",\n",
    "    y_col=\"label\",\n",
    "    seed=0,\n",
    "    target_size=(img_height, img_width),\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    batch_size = 225)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try extracting features to do SVM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = []\n",
    "for i in range(1500):\n",
    "    training_features.append(np.array(base_model(train_generator.next())).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"training_features_InceptionV3.csv\", training_features, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970727896910294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       995\n",
      "           1       0.91      0.81      0.86       505\n",
      "\n",
      "    accuracy                           0.91      1500\n",
      "   macro avg       0.91      0.89      0.90      1500\n",
      "weighted avg       0.91      0.91      0.91      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "labels = train_generator.classes\n",
    "clf = svm.SVC(kernel='rbf', degree = 3, probability=True, C=0.1, gamma='scale')\n",
    "clf.fit(training_features, labels)\n",
    "\n",
    "# Primary evaluation\n",
    "score = clf.predict_proba(training_features)\n",
    "auc = metrics.roc_auc_score(labels, score[:,1])\n",
    "print(auc)\n",
    "print (classification_report(labels, score[:,1]>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf', probability=True, C=1, gamma = 'scale')\n",
    "# Perform cross validated performance assessment\n",
    "prediction_scores = cv_performance_assessment(np.array(training_features),np.array(labels),5,clf)\n",
    "\n",
    "# Compute and plot the ROC curves\n",
    "plot_roc(labels, prediction_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 558 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    batch_size=1\n",
    ")\n",
    "testing_features = []\n",
    "for i in range(558):\n",
    "    testing_features.append(np.array(base_model(test_generator.next())).ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='rbf', probability=True, C=1, gamma = 'scale')\n",
    "clf.fit(training_features, labels)\n",
    "\n",
    "score = clf.predict_proba(testing_features)\n",
    "dir_test_ids      = './data/sample_submission.csv'\n",
    "dir_test_images   = './data/testing/'\n",
    "test_data, ids = load_data(dir_test_images, dir_test_ids, training=False)\n",
    "# Save the predictions to a CSV file for upload to Kaggle\n",
    "submission_file = pd.DataFrame({'id':    ids,\n",
    "                                   'score':  score[:,1]})\n",
    "submission_file.to_csv('Inception_SVM2.csv',\n",
    "                           columns=['id','score'],\n",
    "                           index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.90536866],\n",
       "       [0.90536866, 1.        ]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peer = pd.read_csv('submission_PCA_SVM_3C.csv')\n",
    "peer = pd.read_csv('Inception_SVM.csv')\n",
    "np.corrcoef(score[:,1],np.array(peer.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_mod(lr, weight, name, epoch = 30):\n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # add a logistic layer -- let's say we have 200 classes\n",
    "    predictions = Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, amsgrad=False), \n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    filename = 'D:\\\\MIDS\\\\RedTeam\\\\' +name+ '.csv'\n",
    "    csv_logger = CSVLogger(filename, append=True, separator=';')\n",
    "    \n",
    "    model.fit_generator(train_generator, validation_data=validation_generator ,\n",
    "                        epochs=epoch, class_weight=weight, callbacks=[csv_logger])\n",
    "    \n",
    "    score = model.predict(train_generator)\n",
    "    labels = train_generator.classes\n",
    "    auc = metrics.roc_auc_score(labels, score.ravel())\n",
    "    return (score, labels, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40/40 [==============================] - 21s 524ms/step - loss: 0.7103 - accuracy: 0.5388 - val_loss: 0.7583 - val_accuracy: 0.4756\n",
      "Epoch 2/30\n",
      "40/40 [==============================] - 21s 533ms/step - loss: 0.6732 - accuracy: 0.6314 - val_loss: 0.7028 - val_accuracy: 0.5911\n",
      "Epoch 3/30\n",
      "40/40 [==============================] - 22s 543ms/step - loss: 0.6673 - accuracy: 0.6267 - val_loss: 0.7062 - val_accuracy: 0.6044\n",
      "Epoch 4/30\n",
      "40/40 [==============================] - 22s 548ms/step - loss: 0.6643 - accuracy: 0.6353 - val_loss: 0.6653 - val_accuracy: 0.6356\n",
      "Epoch 5/30\n",
      "40/40 [==============================] - 22s 550ms/step - loss: 0.6603 - accuracy: 0.6494 - val_loss: 0.6536 - val_accuracy: 0.6622\n",
      "Epoch 6/30\n",
      "40/40 [==============================] - 22s 550ms/step - loss: 0.6510 - accuracy: 0.6557 - val_loss: 0.6445 - val_accuracy: 0.6400\n",
      "Epoch 7/30\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.6506 - accuracy: 0.6439 - val_loss: 0.7025 - val_accuracy: 0.6356\n",
      "Epoch 8/30\n",
      "40/40 [==============================] - 22s 553ms/step - loss: 0.6317 - accuracy: 0.6541 - val_loss: 0.6922 - val_accuracy: 0.6622\n",
      "Epoch 9/30\n",
      "40/40 [==============================] - 22s 550ms/step - loss: 0.6405 - accuracy: 0.6463 - val_loss: 0.7149 - val_accuracy: 0.6400\n",
      "Epoch 10/30\n",
      "40/40 [==============================] - 23s 566ms/step - loss: 0.6419 - accuracy: 0.6455 - val_loss: 0.6998 - val_accuracy: 0.6844\n",
      "Epoch 11/30\n",
      "40/40 [==============================] - 22s 553ms/step - loss: 0.6429 - accuracy: 0.6533 - val_loss: 0.6832 - val_accuracy: 0.6756\n",
      "Epoch 12/30\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.6411 - accuracy: 0.6447 - val_loss: 0.6630 - val_accuracy: 0.6800\n",
      "Epoch 13/30\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.6367 - accuracy: 0.6627 - val_loss: 0.6654 - val_accuracy: 0.6667\n",
      "Epoch 14/30\n",
      "40/40 [==============================] - 23s 568ms/step - loss: 0.6414 - accuracy: 0.6447 - val_loss: 0.7100 - val_accuracy: 0.6667\n",
      "Epoch 15/30\n",
      "40/40 [==============================] - 23s 565ms/step - loss: 0.6387 - accuracy: 0.6580 - val_loss: 0.6982 - val_accuracy: 0.6533\n",
      "Epoch 16/30\n",
      "40/40 [==============================] - 23s 573ms/step - loss: 0.6335 - accuracy: 0.6533 - val_loss: 0.6584 - val_accuracy: 0.6578\n",
      "Epoch 17/30\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.6267 - accuracy: 0.6533 - val_loss: 0.7355 - val_accuracy: 0.6578\n",
      "Epoch 18/30\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.6246 - accuracy: 0.6627 - val_loss: 0.6968 - val_accuracy: 0.6578\n",
      "Epoch 19/30\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.6238 - accuracy: 0.6651 - val_loss: 0.6568 - val_accuracy: 0.6622\n",
      "Epoch 20/30\n",
      "40/40 [==============================] - 23s 565ms/step - loss: 0.6186 - accuracy: 0.6667 - val_loss: 0.6707 - val_accuracy: 0.6711\n",
      "Epoch 21/30\n",
      "40/40 [==============================] - 22s 545ms/step - loss: 0.6203 - accuracy: 0.6620 - val_loss: 0.6516 - val_accuracy: 0.6711\n",
      "Epoch 22/30\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.6068 - accuracy: 0.6698 - val_loss: 0.7029 - val_accuracy: 0.6756\n",
      "Epoch 23/30\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.6251 - accuracy: 0.6722 - val_loss: 0.6959 - val_accuracy: 0.6844\n",
      "Epoch 24/30\n",
      "40/40 [==============================] - 23s 572ms/step - loss: 0.6125 - accuracy: 0.6816 - val_loss: 0.6814 - val_accuracy: 0.6667\n",
      "Epoch 25/30\n",
      "40/40 [==============================] - 22s 548ms/step - loss: 0.6153 - accuracy: 0.6698 - val_loss: 0.6365 - val_accuracy: 0.6578\n",
      "Epoch 26/30\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.6135 - accuracy: 0.6714 - val_loss: 0.6477 - val_accuracy: 0.6844\n",
      "Epoch 27/30\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.6114 - accuracy: 0.6627 - val_loss: 0.6280 - val_accuracy: 0.6889\n",
      "Epoch 28/30\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.6200 - accuracy: 0.6729 - val_loss: 0.6704 - val_accuracy: 0.6800\n",
      "Epoch 29/30\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.6076 - accuracy: 0.6729 - val_loss: 0.6591 - val_accuracy: 0.6756\n",
      "Epoch 30/30\n",
      "40/40 [==============================] - 23s 571ms/step - loss: 0.6092 - accuracy: 0.6682 - val_loss: 0.6488 - val_accuracy: 0.6444\n",
      "Epoch 1/30\n",
      "40/40 [==============================] - 26s 661ms/step - loss: 0.8350 - accuracy: 0.5404 - val_loss: 0.7010 - val_accuracy: 0.6089\n",
      "Epoch 2/30\n",
      "40/40 [==============================] - 25s 614ms/step - loss: 0.8212 - accuracy: 0.5718 - val_loss: 0.6996 - val_accuracy: 0.5689\n",
      "Epoch 3/30\n",
      "40/40 [==============================] - 24s 608ms/step - loss: 0.8297 - accuracy: 0.5545 - val_loss: 0.6818 - val_accuracy: 0.5689\n",
      "Epoch 4/30\n",
      "40/40 [==============================] - 25s 614ms/step - loss: 0.8132 - accuracy: 0.5686 - val_loss: 0.6639 - val_accuracy: 0.6222\n",
      "Epoch 5/30\n",
      "40/40 [==============================] - 25s 622ms/step - loss: 0.8147 - accuracy: 0.5741 - val_loss: 0.6984 - val_accuracy: 0.5733\n",
      "Epoch 6/30\n",
      "40/40 [==============================] - 25s 625ms/step - loss: 0.8058 - accuracy: 0.5984 - val_loss: 0.6399 - val_accuracy: 0.6533\n",
      "Epoch 7/30\n",
      "40/40 [==============================] - 26s 639ms/step - loss: 0.7987 - accuracy: 0.6118 - val_loss: 0.6736 - val_accuracy: 0.6622\n",
      "Epoch 8/30\n",
      "40/40 [==============================] - 25s 626ms/step - loss: 0.7990 - accuracy: 0.6078 - val_loss: 0.6898 - val_accuracy: 0.6400\n",
      "Epoch 9/30\n",
      "40/40 [==============================] - 25s 623ms/step - loss: 0.8004 - accuracy: 0.6094 - val_loss: 0.6256 - val_accuracy: 0.6311\n",
      "Epoch 10/30\n",
      "40/40 [==============================] - 25s 615ms/step - loss: 0.8107 - accuracy: 0.5945 - val_loss: 0.6391 - val_accuracy: 0.6756\n",
      "Epoch 11/30\n",
      "40/40 [==============================] - 25s 630ms/step - loss: 0.7904 - accuracy: 0.6212 - val_loss: 0.6564 - val_accuracy: 0.6311\n",
      "Epoch 12/30\n",
      "40/40 [==============================] - 26s 650ms/step - loss: 0.7887 - accuracy: 0.6243 - val_loss: 0.6887 - val_accuracy: 0.6667\n",
      "Epoch 13/30\n",
      "40/40 [==============================] - 24s 609ms/step - loss: 0.7835 - accuracy: 0.6314 - val_loss: 0.6941 - val_accuracy: 0.5822\n",
      "Epoch 14/30\n",
      "40/40 [==============================] - 25s 628ms/step - loss: 0.7759 - accuracy: 0.6220 - val_loss: 0.6397 - val_accuracy: 0.6533\n",
      "Epoch 15/30\n",
      " 8/40 [=====>........................] - ETA: 17s - loss: 0.7923 - accuracy: 0.6454"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-663b4a4b17fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0ma_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN_mod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'run_lr'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'_w'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0ms_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0ml_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-0e5bc5497776>\u001b[0m in \u001b[0;36mCNN_mod\u001b[1;34m(lr, weight, name, epoch)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     model.fit_generator(train_generator, validation_data=validation_generator ,\n\u001b[1;32m---> 28\u001b[1;33m                         epochs=epoch, class_weight=weight, callbacks=[csv_logger])\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = [0.0001, 0.0005, 0.001, 0.01, 0.1]\n",
    "weight = [{0:1., 1:1.}, {0:1., 1:1.5}, {0:1., 1:2.}, {0:1., 1:2.5}]\n",
    "# column in weight, row is lr\n",
    "score_all = []\n",
    "labels_all = []\n",
    "auc_all = []\n",
    "for rate in lr:\n",
    "    s_row = []\n",
    "    l_row = []\n",
    "    a_row = []\n",
    "    for w in weight:\n",
    "        s, l, a = CNN_mod(rate, w, name = 'run_lr'+str(int(rate*10000)) +'_w' + str(int(w[1]*10)), epoch = 30)\n",
    "        s_row.append(s)\n",
    "        l_row.append(l)\n",
    "        a_row.append(a)\n",
    "    score_all.append(s_row)\n",
    "    labels_all.append(l_row)\n",
    "    auc_all.append(a_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, amsgrad=False),\n",
    "#              loss=keras.losses.sparse_categorical_crossentropy,\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbackobj = tf.compat.v1.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0,  \n",
    "#          write_graph=True, write_images=True, write_grads = True, update_freq = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed0\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 average_pooling2d_2\n",
      "51 conv2d_13\n",
      "52 conv2d_15\n",
      "53 conv2d_18\n",
      "54 conv2d_19\n",
      "55 batch_normalization_13\n",
      "56 batch_normalization_15\n",
      "57 batch_normalization_18\n",
      "58 batch_normalization_19\n",
      "59 activation_13\n",
      "60 activation_15\n",
      "61 activation_18\n",
      "62 activation_19\n",
      "63 mixed1\n",
      "64 conv2d_23\n",
      "65 batch_normalization_23\n",
      "66 activation_23\n",
      "67 conv2d_21\n",
      "68 conv2d_24\n",
      "69 batch_normalization_21\n",
      "70 batch_normalization_24\n",
      "71 activation_21\n",
      "72 activation_24\n",
      "73 average_pooling2d_3\n",
      "74 conv2d_20\n",
      "75 conv2d_22\n",
      "76 conv2d_25\n",
      "77 conv2d_26\n",
      "78 batch_normalization_20\n",
      "79 batch_normalization_22\n",
      "80 batch_normalization_25\n",
      "81 batch_normalization_26\n",
      "82 activation_20\n",
      "83 activation_22\n",
      "84 activation_25\n",
      "85 activation_26\n",
      "86 mixed2\n",
      "87 conv2d_28\n",
      "88 batch_normalization_28\n",
      "89 activation_28\n",
      "90 conv2d_29\n",
      "91 batch_normalization_29\n",
      "92 activation_29\n",
      "93 conv2d_27\n",
      "94 conv2d_30\n",
      "95 batch_normalization_27\n",
      "96 batch_normalization_30\n",
      "97 activation_27\n",
      "98 activation_30\n",
      "99 max_pooling2d_3\n",
      "100 mixed3\n",
      "101 conv2d_35\n",
      "102 batch_normalization_35\n",
      "103 activation_35\n",
      "104 conv2d_36\n",
      "105 batch_normalization_36\n",
      "106 activation_36\n",
      "107 conv2d_32\n",
      "108 conv2d_37\n",
      "109 batch_normalization_32\n",
      "110 batch_normalization_37\n",
      "111 activation_32\n",
      "112 activation_37\n",
      "113 conv2d_33\n",
      "114 conv2d_38\n",
      "115 batch_normalization_33\n",
      "116 batch_normalization_38\n",
      "117 activation_33\n",
      "118 activation_38\n",
      "119 average_pooling2d_4\n",
      "120 conv2d_31\n",
      "121 conv2d_34\n",
      "122 conv2d_39\n",
      "123 conv2d_40\n",
      "124 batch_normalization_31\n",
      "125 batch_normalization_34\n",
      "126 batch_normalization_39\n",
      "127 batch_normalization_40\n",
      "128 activation_31\n",
      "129 activation_34\n",
      "130 activation_39\n",
      "131 activation_40\n",
      "132 mixed4\n",
      "133 conv2d_45\n",
      "134 batch_normalization_45\n",
      "135 activation_45\n",
      "136 conv2d_46\n",
      "137 batch_normalization_46\n",
      "138 activation_46\n",
      "139 conv2d_42\n",
      "140 conv2d_47\n",
      "141 batch_normalization_42\n",
      "142 batch_normalization_47\n",
      "143 activation_42\n",
      "144 activation_47\n",
      "145 conv2d_43\n",
      "146 conv2d_48\n",
      "147 batch_normalization_43\n",
      "148 batch_normalization_48\n",
      "149 activation_43\n",
      "150 activation_48\n",
      "151 average_pooling2d_5\n",
      "152 conv2d_41\n",
      "153 conv2d_44\n",
      "154 conv2d_49\n",
      "155 conv2d_50\n",
      "156 batch_normalization_41\n",
      "157 batch_normalization_44\n",
      "158 batch_normalization_49\n",
      "159 batch_normalization_50\n",
      "160 activation_41\n",
      "161 activation_44\n",
      "162 activation_49\n",
      "163 activation_50\n",
      "164 mixed5\n",
      "165 conv2d_55\n",
      "166 batch_normalization_55\n",
      "167 activation_55\n",
      "168 conv2d_56\n",
      "169 batch_normalization_56\n",
      "170 activation_56\n",
      "171 conv2d_52\n",
      "172 conv2d_57\n",
      "173 batch_normalization_52\n",
      "174 batch_normalization_57\n",
      "175 activation_52\n",
      "176 activation_57\n",
      "177 conv2d_53\n",
      "178 conv2d_58\n",
      "179 batch_normalization_53\n",
      "180 batch_normalization_58\n",
      "181 activation_53\n",
      "182 activation_58\n",
      "183 average_pooling2d_6\n",
      "184 conv2d_51\n",
      "185 conv2d_54\n",
      "186 conv2d_59\n",
      "187 conv2d_60\n",
      "188 batch_normalization_51\n",
      "189 batch_normalization_54\n",
      "190 batch_normalization_59\n",
      "191 batch_normalization_60\n",
      "192 activation_51\n",
      "193 activation_54\n",
      "194 activation_59\n",
      "195 activation_60\n",
      "196 mixed6\n",
      "197 conv2d_65\n",
      "198 batch_normalization_65\n",
      "199 activation_65\n",
      "200 conv2d_66\n",
      "201 batch_normalization_66\n",
      "202 activation_66\n",
      "203 conv2d_62\n",
      "204 conv2d_67\n",
      "205 batch_normalization_62\n",
      "206 batch_normalization_67\n",
      "207 activation_62\n",
      "208 activation_67\n",
      "209 conv2d_63\n",
      "210 conv2d_68\n",
      "211 batch_normalization_63\n",
      "212 batch_normalization_68\n",
      "213 activation_63\n",
      "214 activation_68\n",
      "215 average_pooling2d_7\n",
      "216 conv2d_61\n",
      "217 conv2d_64\n",
      "218 conv2d_69\n",
      "219 conv2d_70\n",
      "220 batch_normalization_61\n",
      "221 batch_normalization_64\n",
      "222 batch_normalization_69\n",
      "223 batch_normalization_70\n",
      "224 activation_61\n",
      "225 activation_64\n",
      "226 activation_69\n",
      "227 activation_70\n",
      "228 mixed7\n",
      "229 conv2d_73\n",
      "230 batch_normalization_73\n",
      "231 activation_73\n",
      "232 conv2d_74\n",
      "233 batch_normalization_74\n",
      "234 activation_74\n",
      "235 conv2d_71\n",
      "236 conv2d_75\n",
      "237 batch_normalization_71\n",
      "238 batch_normalization_75\n",
      "239 activation_71\n",
      "240 activation_75\n",
      "241 conv2d_72\n",
      "242 conv2d_76\n",
      "243 batch_normalization_72\n",
      "244 batch_normalization_76\n",
      "245 activation_72\n",
      "246 activation_76\n",
      "247 max_pooling2d_4\n",
      "248 mixed8\n",
      "249 conv2d_81\n",
      "250 batch_normalization_81\n",
      "251 activation_81\n",
      "252 conv2d_78\n",
      "253 conv2d_82\n",
      "254 batch_normalization_78\n",
      "255 batch_normalization_82\n",
      "256 activation_78\n",
      "257 activation_82\n",
      "258 conv2d_79\n",
      "259 conv2d_80\n",
      "260 conv2d_83\n",
      "261 conv2d_84\n",
      "262 average_pooling2d_8\n",
      "263 conv2d_77\n",
      "264 batch_normalization_79\n",
      "265 batch_normalization_80\n",
      "266 batch_normalization_83\n",
      "267 batch_normalization_84\n",
      "268 conv2d_85\n",
      "269 batch_normalization_77\n",
      "270 activation_79\n",
      "271 activation_80\n",
      "272 activation_83\n",
      "273 activation_84\n",
      "274 batch_normalization_85\n",
      "275 activation_77\n",
      "276 mixed9_0\n",
      "277 concatenate_1\n",
      "278 activation_85\n",
      "279 mixed9\n",
      "280 conv2d_90\n",
      "281 batch_normalization_90\n",
      "282 activation_90\n",
      "283 conv2d_87\n",
      "284 conv2d_91\n",
      "285 batch_normalization_87\n",
      "286 batch_normalization_91\n",
      "287 activation_87\n",
      "288 activation_91\n",
      "289 conv2d_88\n",
      "290 conv2d_89\n",
      "291 conv2d_92\n",
      "292 conv2d_93\n",
      "293 average_pooling2d_9\n",
      "294 conv2d_86\n",
      "295 batch_normalization_88\n",
      "296 batch_normalization_89\n",
      "297 batch_normalization_92\n",
      "298 batch_normalization_93\n",
      "299 conv2d_94\n",
      "300 batch_normalization_86\n",
      "301 activation_88\n",
      "302 activation_89\n",
      "303 activation_92\n",
      "304 activation_93\n",
      "305 batch_normalization_94\n",
      "306 activation_86\n",
      "307 mixed9_1\n",
      "308 concatenate_2\n",
      "309 activation_94\n",
      "310 mixed10\n"
     ]
    }
   ],
   "source": [
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.8361 - accuracy: 0.6635 - val_loss: 0.9618 - val_accuracy: 0.5689\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.8466 - accuracy: 0.6431 - val_loss: 0.2992 - val_accuracy: 0.6178\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.8330 - accuracy: 0.6604 - val_loss: 0.1439 - val_accuracy: 0.5867\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.8440 - accuracy: 0.6596 - val_loss: 0.9651 - val_accuracy: 0.6356\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 21s 1s/step - loss: 0.8405 - accuracy: 0.6533 - val_loss: 0.3571 - val_accuracy: 0.6400\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.8084 - accuracy: 0.6855 - val_loss: 0.5333 - val_accuracy: 0.6756\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.8266 - accuracy: 0.6808 - val_loss: 0.8698 - val_accuracy: 0.6044\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 20s 982ms/step - loss: 0.8441 - accuracy: 0.6361 - val_loss: 0.1820 - val_accuracy: 0.5733\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 19s 975ms/step - loss: 0.8342 - accuracy: 0.6118 - val_loss: 0.0325 - val_accuracy: 0.6578\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.8267 - accuracy: 0.6635 - val_loss: 0.8039 - val_accuracy: 0.6178\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 21s 1s/step - loss: 0.8325 - accuracy: 0.6486 - val_loss: 0.8864 - val_accuracy: 0.6089\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 21s 1s/step - loss: 0.8055 - accuracy: 0.6729 - val_loss: 0.3628 - val_accuracy: 0.6444\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.8176 - accuracy: 0.6714 - val_loss: 1.6182 - val_accuracy: 0.5644\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 20s 1s/step - loss: 0.8188 - accuracy: 0.6776 - val_loss: 0.2143 - val_accuracy: 0.5867\n",
      "Epoch 15/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.8073 - accuracy: 0.6713"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-5709c7668618>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the output layer for a few epoches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    240\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m                             workers=0)\n\u001b[0m\u001b[0;32m    243\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                         \u001b[1;31m# No need for try/except because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1789\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1790\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1791\u001b[1;33m             verbose=verbose)\n\u001b[0m\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    399\u001b[0m             outs = model.test_on_batch(x, y,\n\u001b[0;32m    400\u001b[0m                                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m                                        reset_metrics=False)\n\u001b[0m\u001b[0;32m    402\u001b[0m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1557\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1558\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1559\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the output layer for a few epoches\n",
    "model.fit_generator(train_generator, validation_data=validation_generator ,epochs=20, class_weight=class_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4861173108328797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.23      0.34       835\n",
      "           1       0.33      0.73      0.46       440\n",
      "\n",
      "    accuracy                           0.41      1275\n",
      "   macro avg       0.48      0.48      0.40      1275\n",
      "weighted avg       0.52      0.41      0.38      1275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#score = model.predict_generator(validation_generator)\n",
    "#labels = validation_generator.classes\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "score = model.predict(train_generator)\n",
    "labels = train_generator.classes\n",
    "#plot_roc(labels, score.ravel())\n",
    "auc = metrics.roc_auc_score(labels, score.ravel())\n",
    "print(auc)\n",
    "print (classification_report(labels, score.ravel()>=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03731085],\n",
       "       [ 0.10650838],\n",
       "       [-0.13288498],\n",
       "       ...,\n",
       "       [ 0.05345095],\n",
       "       [-0.14360557],\n",
       "       [ 0.04681378]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.get_weights())[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1275"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(score.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# See augmented image\n",
    "train_generator = train_datagen.flow_from_dataframe( \n",
    "    dataframe=traindf,\n",
    "    directory=train_data_dir, \n",
    "    x_col=\"id\",\n",
    "    y_col=\"label\",\n",
    "    seed=0,\n",
    "    batch_size = batch_size,\n",
    "    target_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    save_to_dir = \"D:\\\\MIDS\\\\RedTeam\\\\augmeted_solar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.5902355 , 0.5372161 , 0.5109079 ],\n",
       "          [0.5998315 , 0.5384156 , 0.5145064 ],\n",
       "          [0.579139  , 0.53052855, 0.5059895 ],\n",
       "          ...,\n",
       "          [0.7248187 , 0.68168145, 0.60717165],\n",
       "          [0.72512925, 0.67514575, 0.6109053 ],\n",
       "          [0.719872  , 0.6625721 , 0.60549724]],\n",
       " \n",
       "         [[0.5712325 , 0.5359384 , 0.5020569 ],\n",
       "          [0.57003295, 0.53473884, 0.50325644],\n",
       "          [0.57913446, 0.5358285 , 0.50674504],\n",
       "          ...,\n",
       "          [0.72583854, 0.6827013 , 0.6081915 ],\n",
       "          [0.7241094 , 0.67004657, 0.6119251 ],\n",
       "          [0.7178323 , 0.66155225, 0.60039806]],\n",
       " \n",
       "         [[0.568302  , 0.5352469 , 0.4993898 ],\n",
       "          [0.5738196 , 0.53852546, 0.49946976],\n",
       "          [0.57262015, 0.53732604, 0.5006693 ],\n",
       "          ...,\n",
       "          [0.7268232 , 0.68361545, 0.6092113 ],\n",
       "          [0.7230896 , 0.6649474 , 0.61294496],\n",
       "          [0.71579266, 0.66053236, 0.5952988 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.15690783, 0.25364155, 0.26539102],\n",
       "          [0.16306956, 0.2538244 , 0.26839313],\n",
       "          [0.16605645, 0.2635318 , 0.2803407 ],\n",
       "          ...,\n",
       "          [0.40903306, 0.49536112, 0.3425806 ],\n",
       "          [0.39629376, 0.4942955 , 0.3448725 ],\n",
       "          [0.3830992 , 0.493096  , 0.3472715 ]],\n",
       " \n",
       "         [[0.15792766, 0.25568122, 0.2582521 ],\n",
       "          [0.16510925, 0.25280458, 0.27349237],\n",
       "          [0.16605645, 0.26863104, 0.2823804 ],\n",
       "          ...,\n",
       "          [0.38631323, 0.48021457, 0.35015386],\n",
       "          [0.39351022, 0.4850126 , 0.3477549 ],\n",
       "          [0.40070724, 0.48981056, 0.34535587]],\n",
       " \n",
       "         [[0.1596817 , 0.25551835, 0.25992346],\n",
       "          [0.16605645, 0.25506213, 0.27695283],\n",
       "          [0.1653399 , 0.27229708, 0.2840618 ],\n",
       "          ...,\n",
       "          [0.3341655 , 0.45771104, 0.35772717],\n",
       "          [0.35095856, 0.46490806, 0.35532814],\n",
       "          [0.36775157, 0.4721051 , 0.35292915]]],\n",
       " \n",
       " \n",
       "        [[[0.28486273, 0.3152689 , 0.28292996],\n",
       "          [0.2801476 , 0.31216684, 0.28144097],\n",
       "          [0.29704875, 0.31211534, 0.2826548 ],\n",
       "          ...,\n",
       "          [0.342851  , 0.46092176, 0.36203516],\n",
       "          [0.37842512, 0.48045775, 0.38759938],\n",
       "          [0.47283372, 0.50489074, 0.42904383]],\n",
       " \n",
       "         [[0.3691846 , 0.38094935, 0.31753916],\n",
       "          [0.36769563, 0.37946033, 0.31667057],\n",
       "          [0.33688408, 0.3447615 , 0.30344084],\n",
       "          ...,\n",
       "          [0.34262332, 0.46092176, 0.3615798 ],\n",
       "          [0.38047427, 0.48148236, 0.38930702],\n",
       "          [0.47613513, 0.5053461 , 0.42984074]],\n",
       " \n",
       "         [[0.37895903, 0.39817667, 0.32013547],\n",
       "          [0.37933126, 0.39817667, 0.32050774],\n",
       "          [0.36078882, 0.3622749 , 0.3075504 ],\n",
       "          ...,\n",
       "          [0.34205353, 0.46347895, 0.3679857 ],\n",
       "          [0.3796816 , 0.48283166, 0.39919883],\n",
       "          [0.45141694, 0.4994612 , 0.4260362 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.14064926, 0.196425  , 0.21059646],\n",
       "          [0.11789298, 0.18956384, 0.20088181],\n",
       "          [0.1341759 , 0.19013797, 0.20137827],\n",
       "          ...,\n",
       "          [0.41475332, 0.46257138, 0.40647098],\n",
       "          [0.40230986, 0.46149132, 0.40055242],\n",
       "          [0.3993319 , 0.4603746 , 0.3993116 ]],\n",
       " \n",
       "         [[0.122878  , 0.19443537, 0.20843133],\n",
       "          [0.11789298, 0.19033352, 0.20004532],\n",
       "          [0.14495324, 0.19033352, 0.20396493],\n",
       "          ...,\n",
       "          [0.5060874 , 0.5001307 , 0.44165865],\n",
       "          [0.5036061 , 0.4967706 , 0.43614247],\n",
       "          [0.5001318 , 0.4956538 , 0.43514982]],\n",
       " \n",
       "         [[0.12139807, 0.1942077 , 0.20786212],\n",
       "          [0.11802349, 0.19033352, 0.20015915],\n",
       "          [0.14529476, 0.19033352, 0.20407878],\n",
       "          ...,\n",
       "          [0.5660922 , 0.51674104, 0.4524006 ],\n",
       "          [0.57189703, 0.51762664, 0.4494728 ],\n",
       "          [0.57127666, 0.5175026 , 0.449721  ]]],\n",
       " \n",
       " \n",
       "        [[[0.464476  , 0.45316803, 0.4063376 ],\n",
       "          [0.46813923, 0.4521519 , 0.4066023 ],\n",
       "          [0.44837567, 0.44015878, 0.40094313],\n",
       "          ...,\n",
       "          [0.6719247 , 0.5899553 , 0.47507924],\n",
       "          [0.67190295, 0.589401  , 0.47597364],\n",
       "          [0.674566  , 0.59153134, 0.47916925]],\n",
       " \n",
       "         [[0.46177566, 0.45201075, 0.40595183],\n",
       "          [0.47045377, 0.45369497, 0.40698805],\n",
       "          [0.44991875, 0.44093034, 0.40171465],\n",
       "          ...,\n",
       "          [0.6887528 , 0.6028808 , 0.49619332],\n",
       "          [0.6914157 , 0.6054013 , 0.49847862],\n",
       "          [0.69407874, 0.60912955, 0.497946  ]],\n",
       " \n",
       "         [[0.45907527, 0.45085347, 0.40556604],\n",
       "          [0.4727684 , 0.455238  , 0.40737382],\n",
       "          [0.4514618 , 0.44170186, 0.40248618],\n",
       "          ...,\n",
       "          [0.7082655 , 0.62899095, 0.49510863],\n",
       "          [0.7098181 , 0.6314978 , 0.49468708],\n",
       "          [0.70715517, 0.6293674 , 0.49468708]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.7412863 , 0.73252386, 0.7016109 ],\n",
       "          [0.74075365, 0.7309261 , 0.7005458 ],\n",
       "          [0.7402211 , 0.72932833, 0.6994806 ],\n",
       "          ...,\n",
       "          [0.2799114 , 0.38579378, 0.31791294],\n",
       "          [0.29332757, 0.4027916 , 0.32537985],\n",
       "          [0.27696025, 0.39740026, 0.3083328 ]],\n",
       " \n",
       "         [[0.7387055 , 0.72257864, 0.6933653 ],\n",
       "          [0.73977065, 0.7231113 , 0.69176745],\n",
       "          [0.7408359 , 0.7236438 , 0.6901697 ],\n",
       "          ...,\n",
       "          [0.2810687 , 0.38695106, 0.31752717],\n",
       "          [0.2917845 , 0.40086278, 0.32460833],\n",
       "          [0.2788891 , 0.3981718 , 0.31026164]],\n",
       " \n",
       "         [[0.74482435, 0.7252165 , 0.68418705],\n",
       "          [0.7437591 , 0.72415125, 0.6857848 ],\n",
       "          [0.7426939 , 0.72308606, 0.68738264],\n",
       "          ...,\n",
       "          [0.28222597, 0.38810834, 0.3171414 ],\n",
       "          [0.29024145, 0.39893398, 0.3238368 ],\n",
       "          [0.28081793, 0.39894333, 0.31219047]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.23765516, 0.3252229 , 0.284714  ],\n",
       "          [0.24261902, 0.32418832, 0.2859137 ],\n",
       "          [0.24861747, 0.32418832, 0.28711334],\n",
       "          ...,\n",
       "          [0.48471487, 0.5223025 , 0.46410757],\n",
       "          [0.27316323, 0.39576533, 0.37021366],\n",
       "          [0.28091055, 0.3981624 , 0.34565815]],\n",
       " \n",
       "         [[0.2328604 , 0.33888426, 0.28062662],\n",
       "          [0.23505045, 0.3356418 , 0.2821093 ],\n",
       "          [0.23625012, 0.330843  , 0.28330892],\n",
       "          ...,\n",
       "          [0.43452623, 0.4875753 , 0.4397667 ],\n",
       "          [0.23361452, 0.37312332, 0.3512224 ],\n",
       "          [0.296676  , 0.4065004 , 0.34369394]],\n",
       " \n",
       "         [[0.20266831, 0.31230208, 0.2693107 ],\n",
       "          [0.21202269, 0.32065126, 0.27281252],\n",
       "          [0.2216202 , 0.32904905, 0.27641153],\n",
       "          ...,\n",
       "          [0.3793429 , 0.45617792, 0.41598076],\n",
       "          [0.24978893, 0.38168624, 0.34931955],\n",
       "          [0.2938217 , 0.40459752, 0.33893675]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.26797935, 0.39869812, 0.29804492],\n",
       "          [0.2676028 , 0.39757913, 0.29505378],\n",
       "          [0.27506992, 0.39663854, 0.30158994],\n",
       "          ...,\n",
       "          [0.30313304, 0.34317762, 0.32356977],\n",
       "          [0.31867456, 0.34960765, 0.3288375 ],\n",
       "          [0.35586497, 0.36160454, 0.33843505]],\n",
       " \n",
       "         [[0.2670279 , 0.39869812, 0.296142  ],\n",
       "          [0.26950565, 0.39662772, 0.29695663],\n",
       "          [0.27697277, 0.3985414 , 0.30254135],\n",
       "          ...,\n",
       "          [0.3258712 , 0.34438694, 0.3242777 ],\n",
       "          [0.3135519 , 0.3405729 , 0.32096505],\n",
       "          [0.3087532 , 0.3417726 , 0.32216474]],\n",
       " \n",
       "         [[0.2660765 , 0.39869812, 0.29423913],\n",
       "          [0.27140853, 0.39567629, 0.2988595 ],\n",
       "          [0.27887562, 0.40044427, 0.30349278],\n",
       "          ...,\n",
       "          [0.39047083, 0.3751687 , 0.35125512],\n",
       "          [0.3753608 , 0.36782935, 0.34511542],\n",
       "          [0.35256666, 0.35703218, 0.33551794]]],\n",
       " \n",
       " \n",
       "        [[[0.43932742, 0.43051466, 0.38839006],\n",
       "          [0.43932742, 0.4297579 , 0.3853629 ],\n",
       "          [0.43932742, 0.42900106, 0.38233572],\n",
       "          ...,\n",
       "          [0.19022201, 0.26063868, 0.21187642],\n",
       "          [0.20018409, 0.26487795, 0.21976782],\n",
       "          [0.18718773, 0.25752935, 0.21236967]],\n",
       " \n",
       "         [[0.44220936, 0.4372481 , 0.38074097],\n",
       "          [0.44145253, 0.43573454, 0.38376814],\n",
       "          [0.44069576, 0.43422094, 0.3867953 ],\n",
       "          ...,\n",
       "          [0.18948424, 0.25842538, 0.21187642],\n",
       "          [0.20461066, 0.26856673, 0.22271886],\n",
       "          [0.17759681, 0.25088948, 0.20646754]],\n",
       " \n",
       "         [[0.4488728 , 0.44495124, 0.3878299 ],\n",
       "          [0.44735917, 0.4434376 , 0.38480276],\n",
       "          [0.44584563, 0.44192407, 0.38177553],\n",
       "          ...,\n",
       "          [0.1887465 , 0.25621215, 0.21187642],\n",
       "          [0.20903727, 0.2722556 , 0.22566992],\n",
       "          [0.16800584, 0.2442496 , 0.20056541]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.2706843 , 0.3161964 , 0.26131007],\n",
       "          [0.18397842, 0.28095877, 0.2759784 ],\n",
       "          [0.1264245 , 0.21084099, 0.27255717],\n",
       "          ...,\n",
       "          [0.41152114, 0.42078555, 0.36980516],\n",
       "          [0.41187644, 0.41971958, 0.371148  ],\n",
       "          [0.41187644, 0.41971958, 0.37568876]],\n",
       " \n",
       "         [[0.2669955 , 0.31767192, 0.26647443],\n",
       "          [0.16405876, 0.27210563, 0.2781917 ],\n",
       "          [0.1264245 , 0.19608566, 0.2710817 ],\n",
       "          ...,\n",
       "          [0.40795487, 0.4309137 , 0.3802186 ],\n",
       "          [0.40842634, 0.43006983, 0.37908944],\n",
       "          [0.40918317, 0.42779943, 0.37681904]],\n",
       " \n",
       "         [[0.24803114, 0.30942667, 0.26886144],\n",
       "          [0.14910412, 0.25828746, 0.27730182],\n",
       "          [0.1264245 , 0.20867588, 0.27726287],\n",
       "          ...,\n",
       "          [0.40924656, 0.42364115, 0.37679762],\n",
       "          [0.40795487, 0.42472416, 0.37712386],\n",
       "          [0.40795487, 0.4262378 , 0.37788063]]],\n",
       " \n",
       " \n",
       "        [[[0.40569663, 0.60014206, 0.5758497 ],\n",
       "          [0.40798515, 0.603243  , 0.5766126 ],\n",
       "          [0.40494195, 0.6010204 , 0.5735694 ],\n",
       "          ...,\n",
       "          [0.86638606, 0.8490094 , 0.752238  ],\n",
       "          [0.8678006 , 0.85261023, 0.7540751 ],\n",
       "          [0.8704829 , 0.85663366, 0.75675744]],\n",
       " \n",
       "         [[0.40279537, 0.60014206, 0.5748827 ],\n",
       "          [0.40798515, 0.6022759 , 0.5766126 ],\n",
       "          [0.405909  , 0.6019874 , 0.57453644],\n",
       "          ...,\n",
       "          [0.8803201 , 0.87138945, 0.7665945 ],\n",
       "          [0.88312924, 0.8749056 , 0.7690232 ],\n",
       "          [0.8864821 , 0.87624675, 0.77036434]],\n",
       " \n",
       "         [[0.39989412, 0.60014206, 0.5739156 ],\n",
       "          [0.40798515, 0.6013088 , 0.5766126 ],\n",
       "          [0.40687612, 0.60295457, 0.5755036 ],\n",
       "          ...,\n",
       "          [0.89877856, 0.8811653 , 0.775283  ],\n",
       "          [0.90210855, 0.88248926, 0.77662414],\n",
       "          [0.9027791 , 0.8818187 , 0.7779653 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.4745528 , 0.49759105, 0.49082926],\n",
       "          [0.5241757 , 0.5277671 , 0.510276  ],\n",
       "          [0.57379854, 0.5579432 , 0.5297228 ],\n",
       "          ...,\n",
       "          [0.6576657 , 0.63304025, 0.52378434],\n",
       "          [0.7151434 , 0.63512725, 0.5599124 ],\n",
       "          [0.62309945, 0.6087078 , 0.533513  ]],\n",
       " \n",
       "         [[0.7325708 , 0.65775746, 0.5947109 ],\n",
       "          [0.7305592 , 0.6637927 , 0.6000755 ],\n",
       "          [0.7285474 , 0.66982794, 0.60544014],\n",
       "          ...,\n",
       "          [0.6442598 , 0.63294435, 0.5173398 ],\n",
       "          [0.7271871 , 0.63883364, 0.5614417 ],\n",
       "          [0.6398286 , 0.6177469 , 0.5396353 ]],\n",
       " \n",
       "         [[0.7209891 , 0.6901577 , 0.62421256],\n",
       "          [0.71830684, 0.68948716, 0.62622434],\n",
       "          [0.7156245 , 0.68881655, 0.62823606],\n",
       "          ...,\n",
       "          [0.6674699 , 0.63971394, 0.5337803 ],\n",
       "          [0.703977  , 0.6368995 , 0.54886955],\n",
       "          [0.66497296, 0.62354946, 0.54640496]]]], dtype=float32),\n",
       " array([0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
